{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_iCCMpkHqd_R"
   },
   "source": [
    "# Reinforcement learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "# for allowing abstract methodes (closest thing to interface)\n",
    "from abc import ABC, abstractmethod\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "class Agent(ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def _init_weights(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def copy(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_action(self, observation=None):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def mutate(parents=None, mutation_rate=None):\n",
    "        pass\n",
    "\n",
    "# simulate single training run\n",
    "def simulate_env(env, agent):\n",
    "    observation = env.reset()[0]\n",
    "    done = False\n",
    "\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        # Forward pass through the neural network (manueel geschreven)\n",
    "        action = agent.get_action(observation)\n",
    "\n",
    "        # Take the selected action and observe the next state and reward\n",
    "        observation, reward, terminated, truncated, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "        done = truncated or terminated\n",
    "\n",
    "    return total_reward\n",
    "\n",
    "# train a reinforcment learning agent\n",
    "def train_agent(env, agent, population_size = 50, mutation_rate=0.4, num_generations = 100, num_episodes=5):\n",
    "\n",
    "    # Initialize the population\n",
    "    population = [agent.copy() for _ in range(population_size)]\n",
    "\n",
    "    # number of generations in the algorithm\n",
    "    mutation_reduced = False\n",
    "    best_individual = None\n",
    "    for generation in range(num_generations):\n",
    "        scores = []\n",
    "\n",
    "        # Evaluate each individual in the population\n",
    "        for current_pop in population:\n",
    "            total_reward = 0\n",
    "\n",
    "            # Run multiple episodes to evaluate an individual's performance\n",
    "            for _ in range(num_episodes):\n",
    "                total_reward += simulate_env(env, current_pop)\n",
    "\n",
    "            # Calculate the average score for this individual\n",
    "            scores.append(total_reward / num_episodes)\n",
    "\n",
    "        # Select the top-performing individuals\n",
    "        elite_indices = np.argsort(scores)[-int(0.2 * population_size):]\n",
    "\n",
    "        # Create a new population by mutating and recombining the elite individuals\n",
    "        best_individual = population[elite_indices[-1]]\n",
    "        new_population = [best_individual]  # keep best individual\n",
    "\n",
    "        while len(new_population) < population_size:\n",
    "            indices = np.random.choice(elite_indices, size=agent.num_parents)\n",
    "            parents = [population[index] for index in indices]\n",
    "            new_population.extend(current_pop.mutate(parents, mutation_rate))\n",
    "\n",
    "        population = new_population\n",
    "\n",
    "        # Print the best score in this generation\n",
    "        best_score = max(scores)\n",
    "        if best_score > -100 and not mutation_reduced:\n",
    "            mutation_rate *= 0.1\n",
    "            mutation_reduced = True\n",
    "        print(f\"Generation {generation + 1}: Best Score = {best_score}\")\n",
    "    \n",
    "    # return best individual\n",
    "    return best_individual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic algorithms\n",
    "\n",
    "Dit zijn varianten van evolutionaire algoritmes waarbij gebruik gemaakt wordt van crossover van twee ouders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneticAgent(Agent):\n",
    "    num_parents = 2\n",
    "    \n",
    "    def __init__(self, num_inputs=1, num_outputs=1, hidden_layer_sizes=[]) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_outputs = num_outputs\n",
    "        self.hidden_layers_sizes = hidden_layer_sizes\n",
    "        \n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        #print(self.hidden_layers_sizes)\n",
    "        if len(self.hidden_layers_sizes) == 0:\n",
    "            self.weights = [np.random.randn(self.num_inputs, self.outputs)]\n",
    "        else:\n",
    "            self.weights = []\n",
    "\n",
    "            for index, hidden_layer in enumerate(self.hidden_layers_sizes):\n",
    "                if index == 0:\n",
    "                    self.weights.append(np.random.randn(self.num_inputs, hidden_layer))\n",
    "                else:\n",
    "                    self.weights.append(np.random.randn(self.hidden_layers_sizes[index-1], hidden_layer))\n",
    "                \n",
    "                if index == len(self.hidden_layers_sizes) -1:\n",
    "                    self.weights.append(np.random.randn(hidden_layer, self.num_outputs))\n",
    "                \n",
    "    def copy(self):\n",
    "        agent = GeneticAgent(self.num_inputs, self.num_outputs, self.hidden_layers_sizes)\n",
    "        agent._init_weights()\n",
    "\n",
    "        return agent\n",
    "        \n",
    "\n",
    "    def get_action(self, observation=None):\n",
    "\n",
    "        action_prob = observation\n",
    "\n",
    "        for index, hidden_layer in enumerate(self.weights):\n",
    "            if index == len(self.weights)-1:\n",
    "                # lineaire activatiefunctie\n",
    "                action_prob = np.dot(action_prob, hidden_layer)\n",
    "            else:\n",
    "                # tanh activatiefunctie\n",
    "                action_prob = np.tanh(np.dot(action_prob, hidden_layer))\n",
    "\n",
    "        return np.argmax(action_prob)\n",
    "\n",
    "    def mutate(self, parents=None, mutation_rate=None):\n",
    "        if not isinstance(parents, list) and not isinstance(parents[0], GeneticAgent) and not isinstance(parents[1], GeneticAgent):\n",
    "            return\n",
    "        \n",
    "        total_size = 0\n",
    "        for layer in self.weights:\n",
    "            total_size += layer.size\n",
    "\n",
    "        # crossover\n",
    "        crossover_point1 = np.random.randint(0, total_size-1)\n",
    "        crossover_point2 = np.random.randint(crossover_point1 + 1, total_size)\n",
    "        \n",
    "        # flatten weights\n",
    "        weights_parent1 = np.concatenate([layer.flatten() for layer in parents[0].weights])\n",
    "        weights_parent2 = np.concatenate([layer.flatten() for layer in parents[1].weights])\n",
    "\n",
    "        # crossover weights\n",
    "        child_weights1 = np.concatenate((weights_parent1[:crossover_point1], weights_parent2[crossover_point1:crossover_point2], weights_parent1[crossover_point2:]), axis=0)\n",
    "        child_weights2 = np.concatenate((weights_parent2[:crossover_point1], weights_parent1[crossover_point1:crossover_point2], weights_parent2[crossover_point2:]), axis=0)\n",
    "\n",
    "        # recreate shapes\n",
    "        stop_point = 0\n",
    "        child1 = parents[0].copy()\n",
    "        child2 = parents[1].copy()\n",
    "\n",
    "        for index, layer in enumerate(self.hidden_layers_sizes):\n",
    "            if index == 0:\n",
    "                size = self.num_inputs * layer\n",
    "            else:\n",
    "                size = self.hidden_layers_sizes[index-1]\n",
    "\n",
    "            target_shape = parents[0].weights[0].shape\n",
    "            child1.weights[index] = child_weights1[stop_point:stop_point+size].reshape(target_shape)\n",
    "            child2.weights[index] = child_weights2[stop_point:stop_point+size].reshape(target_shape)\n",
    "\n",
    "            stop_point += size\n",
    "        \n",
    "        return [child1, child2]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the MountainCar environment\n",
    "env = gym.make(\"MountainCar-v0\")\n",
    "\n",
    "# Hyperparameters\n",
    "population_size = 100\n",
    "mutation_rate = 0.4\n",
    "num_generations = 100\n",
    "num_episodes = 5\n",
    "\n",
    "# RL agent with internally a NN with a hidden layer of 8 neurons\n",
    "input_size = env.observation_space.shape[0]\n",
    "output_size = env.action_space.n\n",
    "agent = GeneticAgent(num_inputs=input_size, num_outputs=output_size, hidden_layer_sizes=[8])\n",
    "\n",
    "best_genetic_agent = train_agent(env, agent, population_size=population_size, mutation_rate=mutation_rate, num_generations=num_generations, num_episodes=num_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best individual\n",
    "env = gym.make(\"MountainCar-v0\", render_mode=\"human\")\n",
    "\n",
    "for episode in range(5):\n",
    "    score = simulate_env(env, best_genetic_agent)\n",
    "    print(f\"Best Individual Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_action_space(agent):\n",
    "\n",
    "    results = []\n",
    "    xs = np.arange(-1.2, 0.6, 0.05)\n",
    "    ys = np.arange(-0.07, 0.07, 0.001)\n",
    "\n",
    "    for x in xs:\n",
    "        tmp = []\n",
    "        for y in ys:\n",
    "            tmp.append(agent.get_action(np.array([x, y])))\n",
    "        results.append(tmp)\n",
    "    results = np.array(results)\n",
    "    \n",
    "    plt.figure(figsize=(8, 12))\n",
    "    plt.imshow(results, cmap='gray', interpolation='none', extent=[xs[0], xs[-1], ys[0], ys[-1]])\n",
    "\n",
    "    # Add x and y ticks with labels\n",
    "    plt.xticks(np.linspace(xs[0], xs[-1], num=10), rotation=45)  # Set x-axis ticks\n",
    "    plt.yticks(np.linspace(ys[0], ys[-1], num=10))                # Set y-axis ticks\n",
    "    \n",
    "    # Label the axes\n",
    "    plt.xlabel('position')\n",
    "    plt.ylabel('velocity')\n",
    "\n",
    "plot_action_space(best_genetic_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Met pytorch\n",
    "\n",
    "Pas het genetisch algoritme in voorgaande code aan zodat er gebruik gemaakt wordt van pytorch inplaats van de berekeningen manueel met wiskunde operaties te doen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create agent met klassenaam GeneticTFAgent\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "class GeneticTorchAgent(Agent):\n",
    "    num_parents = 2\n",
    "    \n",
    "    def __init__(self, num_inputs=1, num_outputs=1, hidden_layer_sizes=[]) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_outputs = num_outputs\n",
    "        self.hidden_layers_sizes = hidden_layer_sizes\n",
    "        \n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "\n",
    "        layers = []\n",
    "        input_size = self.num_inputs\n",
    "\n",
    "        for hidden_size in self.hidden_layers_sizes:\n",
    "            layers.append(nn.Linear(input_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_size = hidden_size\n",
    "\n",
    "        layers.append(nn.Linear(input_size, self.num_outputs))  # Output layer\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "                \n",
    "    def copy(self):\n",
    "        agent = GeneticTorchAgent(self.num_inputs, self.num_outputs, self.hidden_layers_sizes)\n",
    "        agent.model.load_state_dict(self.model.state_dict())  # Copy weights\n",
    "        return agent\n",
    "        \n",
    "\n",
    "    def get_action(self, observation=None):\n",
    "        with torch.no_grad():\n",
    "            observation_tensor = torch.FloatTensor(observation).unsqueeze(0)  # Add batch dimension\n",
    "            action_prob = self.model(observation_tensor)\n",
    "        return torch.argmax(action_prob).item()\n",
    "\n",
    "    def mutate(self, parents=None, mutation_rate=None):\n",
    "        if not isinstance(parents, list) and not isinstance(parents[0], GeneticTFAgent) and not isinstance(parents[1], GeneticTFAgent):\n",
    "            return\n",
    "        \n",
    "        child1 = parents[0].copy()\n",
    "        child2 = parents[1].copy()\n",
    "        \n",
    "        # Get the weights of the parents and children\n",
    "        parent1_weights = np.concatenate([param.detach().cpu().numpy().flatten() for param in parents[0].model.parameters()])\n",
    "        parent2_weights = np.concatenate([param.detach().cpu().numpy().flatten() for param in parents[1].model.parameters()])\n",
    "\n",
    "        # Perform two-point crossover on weights\n",
    "        crossover_point1 = np.random.randint(0, len(parent1_weights)-1)\n",
    "        crossover_point2 = np.random.randint(crossover_point1 + 1, len(parent1_weights))\n",
    "\n",
    "        # crossover weights\n",
    "        child_weights1 = np.concatenate((parent1_weights[:crossover_point1], parent2_weights[crossover_point1:crossover_point2], parent1_weights[crossover_point2:]), axis=0)\n",
    "        child_weights2 = np.concatenate((parent2_weights[:crossover_point1], parent1_weights[crossover_point1:crossover_point2], parent2_weights[crossover_point2:]), axis=0)\n",
    "        \n",
    "        # mutation\n",
    "        child_weights1 += mutation_rate * np.random.randn(*child_weights1.shape)\n",
    "        child_weights2 += mutation_rate * np.random.randn(*child_weights2.shape)\n",
    "\n",
    "        # recreate shapes\n",
    "        child1_reshaped_weights = []\n",
    "        child2_reshaped_weights = []\n",
    "        idx = 0\n",
    "        for layer in parent1_weights:\n",
    "            size = layer.size\n",
    "            child1_reshaped_weights.append(child_weights1[idx:idx+size].reshape(layer.shape))\n",
    "            child2_reshaped_weights.append(child_weights2[idx:idx+size].reshape(layer.shape))\n",
    "            idx += size\n",
    "\n",
    "        # Set the weights back to the children\n",
    "        with torch.no_grad():\n",
    "            for child1_param, child2_param, new_w1, new_w2 in zip(child1.model.parameters(), child2.model.parameters(), child1_reshaped_weights, child2_reshaped_weights):\n",
    "                child1_param.copy_(torch.from_numpy(new_w1))\n",
    "                child2_param.copy_(torch.from_numpy(new_w2))\n",
    "        \n",
    "        return [child1, child2]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the MountainCar environment\n",
    "env = gym.make(\"MountainCar-v0\")\n",
    "\n",
    "# Hyperparameters\n",
    "population_size = 100\n",
    "mutation_rate = 0.4\n",
    "num_generations = 100\n",
    "num_episodes = 5\n",
    "\n",
    "# RL agent with internally a NN with a hidden layer of 8 neurons\n",
    "input_size = env.observation_space.shape[0]\n",
    "output_size = env.action_space.n\n",
    "agent = GeneticTorchAgent(num_inputs=input_size, num_outputs=output_size, hidden_layer_sizes=[8])\n",
    "\n",
    "best_genetictorch_agent = train_agent(env, agent, population_size=population_size, mutation_rate=mutation_rate, num_generations=num_generations, num_episodes=num_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best individual\n",
    "env = gym.make(\"MountainCar-v0\", render_mode=\"human\")\n",
    "\n",
    "for episode in range(5):\n",
    "    score = simulate_env(env, best_genetictorch_agent)\n",
    "    print(f\"Best Individual Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_action_space(best_genetictf_agent)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "d5e8e3a19af5ceb2434683dff87da6345c3b29f7eb0a8a138558c07d014a01cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
