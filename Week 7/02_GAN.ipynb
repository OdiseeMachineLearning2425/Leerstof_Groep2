{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73e730cc-69c0-4b82-bb58-25a163fa4aad",
   "metadata": {},
   "source": [
    "# GAN met Fashion MNIST\n",
    "\n",
    "In deze notebook gaan we opnieuw beelden genereren op basis van de Fashin MNIST dataset, net zoals in de vorige notebook over variational autoencoders (VAE). \n",
    "Hierbij moeten we een generator en discriminator opstellen.\n",
    "\n",
    "## Importeren van packages en dataset\n",
    "\n",
    "Eerst importeren we alle benodigde Python-bibliotheken voor het bouwen, trainen en visualiseren van onze VAE.\n",
    "We gebruiken Pytorch voor het bouwen van het neurale netwerk, matplotlib voor visualisaties en NumPy voor numerieke berekeningen.\n",
    "Daarna laden we de Fashion MNIST dataset, normaliseren de pixelwaarden naar de range [-1,1] \n",
    "en splitsen de dataset in een trainings- en testset. We gebruiken DataLoader om mini-batches te maken voor training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1737c9cf-73df-433c-95b1-aa0c9e36f383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data geladen en DataLoader klaar.\n"
     ]
    }
   ],
   "source": [
    "# Importeren van benodigde bibliotheken\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Controleer of er een GPU beschikbaar is, zo niet gebruik de CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data-transformatie: normaliseer de afbeeldingen zodat de pixelwaarden tussen -1 en 1 liggen\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Converteert beeld naar tensor\n",
    "    transforms.Normalize((0,), (1,))  # Normaliseert naar bereik [-1, 1]\n",
    "])\n",
    "\n",
    "# FashionMNIST dataset downloaden en laden\n",
    "train_dataset = datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
    "\n",
    "# DataLoader voor batches van de trainingsdata\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "print(\"Data geladen en DataLoader klaar.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fe9ec8-a50e-43bf-beb2-6512baea7425",
   "metadata": {},
   "source": [
    "## Generator\n",
    "\n",
    " Deze cel definieert de generator die een random vector van ruis (latent vector) gebruikt om een afbeelding van 28x28 pixels te genereren. Het netwerk bestaat uit vier volledig verbonden lagen met ReLU-activatie, gevolgd door een Tanh activatie om de output te normaliseren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "874fb7ab-4bd0-4f04-af4f-f2d83ca3f8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=100, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=1024, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=1024, out_features=784, bias=True)\n",
      "    (7): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, output_dim),\n",
    "            nn.Tanh() # zodat de outputwaarden tussen -1 en 1 liggen\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "latent_dim = 100\n",
    "generator = Generator(100, 28*28)\n",
    "print(generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcf2452-9b43-4d32-aad2-54b6b5f935a8",
   "metadata": {},
   "source": [
    "## Discriminator\n",
    "\n",
    "Deze cel definieert de discriminator, die een afbeelding van 28x28 pixels als invoer ontvangt en een enkele waarde teruggeeft die aangeeft of de afbeelding echt is (uit de dataset) of vals (gegenereerd door de generator). Het netwerk bestaat uit vier volledig verbonden lagen met LeakyReLU-activatie en dropout om overfitting te voorkomen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bbe85dc-37df-4501-9767-b5636cf04030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=1024, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (4): LeakyReLU(negative_slope=0.01)\n",
      "    (5): Dropout(p=0.3, inplace=False)\n",
      "    (6): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (7): LeakyReLU(negative_slope=0.01)\n",
      "    (8): Dropout(p=0.3, inplace=False)\n",
      "    (9): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (10): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024,512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512,256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "discriminator = Discriminator(28*28)\n",
    "print(discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a07f9a-1b9d-4548-867f-1c7e72369ecd",
   "metadata": {},
   "source": [
    "## Loss functions\n",
    "\n",
    "In deze cel worden de verliesfunctie en de optimalizers voor de generator en discriminator gedefinieerd. We gebruiken binaire cross-entropy (BCELoss) als verliesfunctie en de Adam-optimizer voor zowel de generator als de discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6f3fcc3-2f36-4882-81ef-75cdeccbb41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss() # loss function voor de descriminator\n",
    "\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.002)\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=0.002)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f861192-bcd6-4ea3-8b46-d668028f696c",
   "metadata": {},
   "source": [
    "## Trainen van het GAN model\n",
    "\n",
    "De discriminator wordt getraind met zowel echte als gegenereerde afbeeldingen om te leren onderscheid te maken tussen de twee, terwijl de generator wordt getraind om betere afbeeldingen te genereren die de discriminator niet kan onderscheiden van echte. Voor elke epoch printen we het verlies van zowel de generator als de discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc0d4d1a-46a5-40d3-b256-0fbf3ec86189",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, real_labels) \u001b[38;5;66;03m# hij had eigenlijk moeten voorspellen dat het echte waren\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     optimizer_G\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 29\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     optimizer_G\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for n, (real_images, _) in enumerate(train_loader):\n",
    "        batch_size = real_images.size(0)\n",
    "        # Train Discriminator - real images\n",
    "        real_images = real_images.view(batch_size, -1) # flatten de images\n",
    "        real_labels = torch.ones(batch_size, 1) # elke figuur heeft klasse 1 = echt\n",
    "        outputs = discriminator(real_images)\n",
    "        loss_real = criterion(outputs, real_labels)\n",
    "        optimizer_D.zero_grad()\n",
    "        loss_real.backward()\n",
    "\n",
    "        # Train Discriminator - fake images\n",
    "        noise = torch.randn(batch_size, latent_dim) # ruis met dimensie (batchsize, latent_dim)\n",
    "        fake_images = generator(noise)\n",
    "        fake_labels = torch.zeros(batch_size, 1) # elke figuur heeft klasse 0 = fake\n",
    "        outputs = discriminator(fake_images)\n",
    "        loss_fake = criterion(outputs, fake_labels)\n",
    "        loss_fake.backward()\n",
    "        \n",
    "        optimizer_D.step() # na deze stap heeft de discriminator een optimalisatie uitgevoerd\n",
    "\n",
    "        loss_D = loss_real + loss_fake\n",
    "\n",
    "        # Train generator\n",
    "        outputs = discriminator(fake_images)\n",
    "        loss = criterion(outputs, real_labels) # hij had eigenlijk moeten voorspellen dat het echte waren\n",
    "        optimizer_G.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "    print(f\"Epoch {epoch}/{num_epochs}\")\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bcff63-ec4a-46cb-a2c9-b559bbe75a04",
   "metadata": {},
   "source": [
    "## Visualiseren van de resultaten\n",
    "\n",
    "Deze cel definieert een functie om enkele gegenereerde afbeeldingen van de getrainde generator te visualiseren. Het genereert willekeurige ruis en laat de generator nieuwe afbeeldingen maken, die vervolgens worden weergegeven met behulp van Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2e57ab-d145-4323-b05f-60ccedbb39b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
