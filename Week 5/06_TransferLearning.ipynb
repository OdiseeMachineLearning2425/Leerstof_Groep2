{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f419706-decc-4a30-b2b0-70846e4ff91d",
   "metadata": {},
   "source": [
    "# Transfer learning met PyTorch\n",
    "\n",
    "In deze notebook gaan we het concept van transfer learning onderzoeken. Transfer learning is een techniek waarbij een pre-trained neuraal netwerk wordt gebruikt als startpunt voor een nieuwe taak. Er zijn twee belangrijke benaderingen binnen transfer learning:\n",
    "\n",
    "1. **Feature Extractie**: Hierbij houden we de gewichten van het pre-trained model vast en gebruiken we het model als feature extractor. Alleen het laatste (geclassificeerde) deel van het netwerk wordt aangepast aan de nieuwe taak.\n",
    "  \n",
    "2. **Fine-Tuning**: Hierbij worden de gewichten van (een deel van) het pre-trained model verder getraind op de nieuwe taak. Dit maakt het mogelijk om het model verder aan te passen aan de specifieke data.\n",
    "\n",
    "## Stappen in de notebook\n",
    "\n",
    "1. **Data voorbereiding**:\n",
    "   - We gebruiken een kleine dataset voor classificatie (bijvoorbeeld een subset van de CIFAR-10 dataset).\n",
    "\n",
    "2. **Model laden en voorbereiden**:\n",
    "   - We laden een pre-trained model (bijv. ResNet-18) uit PyTorch's `torchvision` bibliotheek.\n",
    "   - We maken aanpassingen voor beide benaderingen van transfer learning.\n",
    "\n",
    "3. **Training**:\n",
    "   - We demonstreren zowel de **feature extractie** als de **fine-tuning** methode.\n",
    "   - We trainen de laatste laag voor de feature extractie en een deel van het netwerk voor fine-tuning.\n",
    "\n",
    "4. **Evaluatie**:\n",
    "   - We evalueren de prestaties van beide benaderingen op een testset.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Data Voorbereiding\n",
    "\n",
    "We beginnen met het importeren van de benodigde bibliotheken en het laden van de dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b446b01c-c445-480e-8d8a-fbf2f1f9b695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import random\n",
    "\n",
    "# Data transformaties\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),  # Resize to 224x224 pixels (resize 256 en de center crop tegelijkertijd gedaan)\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "# de preprocessing stappen kan je halen uit de beschrijving van het model (bvb op de pytorch api\n",
    "#transform = torchvision.models.ResNet18_Weights.IMAGENET1K_V1.transforms\n",
    "\n",
    "# Laden van de CIFAR-10 dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "total_samples = len(trainset)\n",
    "sample_size = int(0.01 * total_samples)\n",
    "random_indices = random.sample(range(total_samples), sample_size)\n",
    "trainset_reduced = Subset(trainset, random_indices)\n",
    "trainloader = DataLoader(trainset_reduced, batch_size=32, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "total_samples = len(testset)\n",
    "sample_size = int(0.01 * total_samples)\n",
    "random_indices = random.sample(range(total_samples), sample_size)\n",
    "testset_reduced = Subset(testset, random_indices)\n",
    "\n",
    "# Create a DataLoader for the reduced dataset\n",
    "testloader = DataLoader(testset_reduced, batch_size=32, shuffle=True)\n",
    "\n",
    "# Klassen in CIFAR-10\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35834ee8-aaeb-4629-b08a-b24c971930de",
   "metadata": {},
   "source": [
    "## 2. Model Laden en Voorbereiden\n",
    "\n",
    "### A) Feature Extractie\n",
    "\n",
    "In deze aanpak houden we de gewichten van het pre-trained model vast en passen we alleen de laatste laag aan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0c803f4-3066-4fdf-89fd-10e11e73b7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained output shape torch.Size([32, 1000])\n",
      "transfer learned output shape torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "# fe voor feature extraction\n",
    "model_fe = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1) # je moet de weigths meegeven anders enkel de structuur en niet getrained\n",
    "\n",
    "for inputs, labels in trainloader:\n",
    "    print('pretrained output shape', model_fe(inputs).shape)\n",
    "    break\n",
    "\n",
    "for param in model_fe.parameters():\n",
    "    param.requires_grad = False # deze laag wordt niet getrained\n",
    "\n",
    "#print(model_ft)\n",
    "# fc gedeelte onderaan bevat het fully-connected gedeelte -> dit gaan we vervangen\n",
    "num_ftrs_in = model_fe.fc.in_features # 512\n",
    "model_fe.fc = nn.Linear(num_ftrs_in, 10) # 10 want cifar10\n",
    "\n",
    "for inputs, labels in trainloader:\n",
    "    print('transfer learned output shape', model_fe(inputs).shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a71199d-e20c-4d5b-bfbc-bb79bdff2274",
   "metadata": {},
   "source": [
    "### B) Fine-Tuning\n",
    "\n",
    "In deze aanpak staan we toe dat sommige (of alle) gewichten verder worden getraind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1d74949-e58e-48f5-823f-f53cbc9163ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained output shape torch.Size([32, 1000])\n",
      "transfer learned output shape torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "model_ft = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1) # je moet de weigths meegeven anders enkel de structuur en niet getrained\n",
    "\n",
    "for inputs, labels in trainloader:\n",
    "    print('pretrained output shape', model_ft(inputs).shape)\n",
    "    break\n",
    "\n",
    "for name, param in model_ft.named_parameters():\n",
    "    # train het model enkel vanaf de layer 4 (laatste convolutionele blok)\n",
    "    if \"layer_4\" in name or \"fc\" in name:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False # deze laag wordt niet getrained\n",
    "\n",
    "#print(model_ft)\n",
    "# fc gedeelte onderaan bevat het fully-connected gedeelte -> dit gaan we vervangen\n",
    "num_ftrs_in = model_ft.fc.in_features # 512\n",
    "model_ft.fc = nn.Linear(num_ftrs_in, 10) # 10 want cifar10\n",
    "\n",
    "for inputs, labels in trainloader:\n",
    "    print('transfer learned output shape', model_ft(inputs).shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d131b383-34c3-4bc1-96ea-b27ad010324a",
   "metadata": {},
   "source": [
    "## 3. Training\n",
    "\n",
    "Hier zullen we beide modellen trainen, eerst het model voor feature extractie, gevolgd door het model voor fine-tuning.\n",
    "\n",
    "### A) Feature Extractie Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "525a435f-1252-4d92-b229-f40acd796915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/5: time = 11.83214259147644, loss = 2.156807690858841\n",
      "Epoch 1/5: time = 7.916046380996704, loss = 1.7110102325677872\n",
      "Epoch 2/5: time = 7.726578235626221, loss = 1.4230331107974052\n",
      "Epoch 3/5: time = 7.842657804489136, loss = 1.2272974774241447\n",
      "Epoch 4/5: time = 8.521524906158447, loss = 1.1023725494742393\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_fe = optim.Adam(model_fe.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs=5\n",
    "model_fe.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for inputs, labels in trainloader:\n",
    "        optimizer_fe.zero_grad()\n",
    "        outputs = model_fe(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_fe.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"Epoch {epoch}/{num_epochs}: time = {end_time-start_time}, loss = {running_loss/len(trainloader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ac6ede-4350-4275-ac09-268fd39aa2c6",
   "metadata": {},
   "source": [
    "### B) Fine-Tuning Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "939bd4ab-97f3-44e4-a626-febf32029c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/5: time = 8.349033832550049, loss = 2.242882765829563\n",
      "Epoch 1/5: time = 8.441033124923706, loss = 1.7592771798372269\n",
      "Epoch 2/5: time = 8.326905250549316, loss = 1.4430682510137558\n",
      "Epoch 3/5: time = 8.53514838218689, loss = 1.2416529953479767\n",
      "Epoch 4/5: time = 8.847198009490967, loss = 1.1138600558042526\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs=5\n",
    "model_ft.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for inputs, labels in trainloader:\n",
    "        optimizer_ft.zero_grad()\n",
    "        outputs = model_ft(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_ft.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"Epoch {epoch}/{num_epochs}: time = {end_time-start_time}, loss = {running_loss/len(trainloader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22f8f91-e70e-4c36-96b2-d31f5b8fc233",
   "metadata": {},
   "source": [
    "## 4. Evaluatie\n",
    "Na het trainen evalueren we de prestaties van beide modellen op de testset.\n",
    "\n",
    "### A) Evaluatie van het Feature Extractie Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f023adf2-831e-489b-930f-de6ad709101f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is : 69.0\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "model_fe.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in testloader:\n",
    "        outputs = model_fe(inputs)\n",
    "        _, predictions = torch.max(outputs, 1) # maximale_waarden , indices\n",
    "        total += labels.size(0) # batch_size\n",
    "        correct += (predictions == labels).sum().item()\n",
    "\n",
    "print('Accuracy is :', correct/total*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8e21ae-b474-4a6c-b171-3e6fd5d8c7bf",
   "metadata": {},
   "source": [
    "### B) Evaluatie van het Fine-Tuning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24afef41-9712-48df-8a5d-00721780fc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is : 68.0\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "model_ft.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in testloader:\n",
    "        outputs = model_ft(inputs)\n",
    "        _, predictions = torch.max(outputs, 1) # maximale_waarden , indices\n",
    "        total += labels.size(0) # batch_size\n",
    "        correct += (predictions == labels).sum().item()\n",
    "\n",
    "print('Accuracy is :', correct/total*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e037cdb-974e-4fad-9b83-a35106145aac",
   "metadata": {},
   "source": [
    "## Oefening: transfer learning met extra lagen voor FashionMNIST\n",
    "\n",
    "### Oefeningomschrijving:\n",
    "In deze oefening ga je een neuraal netwerk trainen met de FashionMNIST dataset, gebruikmakend van transfer learning. Je zult een pre-trained ResNet-18 model gebruiken, en daar drie extra volledig verbonden lagen aan toevoegen. Vervolgens train je het model en evalueer je de prestaties.\n",
    "\n",
    "### Stappen:\n",
    "\n",
    "**Data Voorbereiding:**\n",
    "\n",
    "Laad de FashionMNIST dataset en breng de nodige transformaties aan.\n",
    "Splits de data in een trainingsset en een testset.\n",
    "\n",
    "**Model Voorbereiding:**\n",
    "\n",
    "Laad een pre-trained ResNet-18 model.\n",
    "Pas het model aan door drie extra volledig verbonden lagen toe te voegen:\n",
    "* De eerste extra laag moet 512 neuronen hebben en een ReLU activatiefunctie.\n",
    "* De tweede extra laag moet 256 neuronen hebben en een ReLU activatiefunctie.\n",
    "* De derde extra laag moet 128 neuronen hebben en een ReLU activatiefunctie.\n",
    "* De laatste output laag moet het aantal klassen in FashionMNIST (10 klassen) bevatten.\n",
    "\n",
    "**Training:**\n",
    "\n",
    "Definieer een loss-functie en een optimizer.\n",
    "Train het model voor een aantal epochs.\n",
    "Meet en print de tijd die elke epoch kost.\n",
    "\n",
    "**Evaluatie:**\n",
    "\n",
    "Evalueer de prestaties van het getrainde model op de testset en rapporteer de accuraatheid.\n",
    "\n",
    "**Vragen om te beantwoorden:**\n",
    "\n",
    "* Wat is het effect van de extra lagen op de prestaties van het model?\n",
    "* Hoeveel tijd kost elke epoch en hoe varieert dit met het aantal lagen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bc1812-c1ef-4699-96b3-831aed35ea62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import time\n",
    "\n",
    "# Transformaties voor de FashionMNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),  # ResNet vereist 3 kanalen\n",
    "    transforms.Resize((224, 224)),               # ResNet vereist input van 224x224\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "# Laad de dataset en splits in train/test sets\n",
    "dataset = FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Laad het pre-trained ResNet-18 model\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False  # Freeze pre-trained lagen\n",
    "\n",
    "# Pas de laatste lagen van het model aan\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 10)  # Output laag voor 10 klassen\n",
    ")\n",
    "\n",
    "# Definieer de loss-functie en optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "# Training van het model\n",
    "num_epochs = 5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_time = time.time() - start_time\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Time: {epoch_time:.2f}s\")\n",
    "\n",
    "# Evaluatie van het model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Test Accuracy: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eec55b-2f7c-46c4-b1f4-3c2c4ac52857",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
