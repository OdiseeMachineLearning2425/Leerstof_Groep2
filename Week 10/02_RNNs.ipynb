{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ece9ec2a-8afa-4f7f-bfe9-0609d1100f6b",
   "metadata": {},
   "source": [
    "# Classificatie van nieuwsartikelen\n",
    "\n",
    "In deze notebook gaan we verder werken op de AG-news nieuwsartikelen dataset.\n",
    "In de vorige notebook hebben we bekeken hoe we tekstuele data kunnen preprocessen.\n",
    "In deze notebook gaan we classificatie uitvoeren door gebruik te maken van recurrente neurale netwerken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7c6d37-e785-4177-9e0d-8cebff1cbd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from keras_preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import opendatasets as od\n",
    "\n",
    "od.download(\"https://www.kaggle.com/datasets/amananandrai/ag-news-classification-dataset\")\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the dataset\n",
    "\n",
    "# Parameters\n",
    "\n",
    "# Tokenizer\n",
    "\n",
    "# Dataset + dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdd6c70-ace6-4e59-8973-b6a60f61fadf",
   "metadata": {},
   "source": [
    "## Opbouwen, trainen en evalueren van een RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f036a6-5932-4948-aa2f-ce4129738238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN model\n",
    "\n",
    "# Train het Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb57af5-0ff0-499f-94be-35e7e5ea89e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalueer het Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6277e4fc-e559-4f43-8d88-1840cc31dc52",
   "metadata": {},
   "source": [
    "## Oefeningen\n",
    "\n",
    "* Voeg een extra Dense-laag toe na de RNN-laag. Experimenteer met het aantal neuronen in deze laag en analyseer hoe de prestaties veranderen.\n",
    "* Pas het model aan om in plaats van een SimpleRNN-laag een LSTM of GRU-laag te gebruiken. Vergelijk de prestaties van de drie typen recurrente netwerken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8991aec0-9549-4d1b-99fb-897d2331fb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oefening 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7775c80b-0838-4a41-848a-25c499141be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oefening 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0a7182-6e98-40a4-953d-3051cb8687a9",
   "metadata": {},
   "source": [
    "**Oefening 3**\n",
    "\n",
    "Volg de tutorial op de volgende link: https://www.tensorflow.org/text/tutorials/text_generation\n",
    "Werk hieronder het gelijkaardige probleem uit maar maak het door gebruik te maken van pytorch in plaats van tensorflow voor het model op te bouwen.\n",
    "In deze tutorial wordt er tekst gegenereerd die lijkt op tekst geschreven door shakespeare.\n",
    "Let op dat dit een vereenvoudigde versie is waarbij karakter per karakter wordt gegenereerd en niet woord per woord. Er is dus geen garantie dat er echte woorden gemaakt worden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edab02f2-fa9f-4306-8ad2-a378b45eb9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import random\n",
    "\n",
    "path_to_file = keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "print(f'Length of text: {len(text)} characters')\n",
    "print(text[:250])\n",
    "# The unique characters in the file\n",
    "vocab = sorted(set(text))\n",
    "print(f'{len(vocab)} unique characters')\n",
    "\n",
    "# Character to index mapping\n",
    "char_to_idx = {char: idx for idx, char in enumerate(vocab)}\n",
    "idx_to_char = {idx: char for idx, char in enumerate(vocab)}\n",
    "\n",
    "# TODO: Encodeer elk karakter in tekst naar een nummer, uitkomst is een list ipv een string\n",
    "\n",
    "# TODO: Maak een dataset aan waarbij de tekst (uit voorgaande todo) omzet naar een reeks sequenties\n",
    "# input 100 aaneensluitende karakters, output is het karakter erop volgende\n",
    "\n",
    "# TODO: indien nodig maak een subset tot 10 of 1% van de dataset\n",
    "\n",
    "# Check a single example\n",
    "sample_x, sample_y = dataset[0]\n",
    "print(\"Input (x):\", sample_x)\n",
    "print(\"Target (y):\", sample_y)\n",
    "print(\"Decoded Input:\", ''.join(idx_to_char[idx] for idx in sample_x.numpy()))\n",
    "print(\"Decoded Target:\", idx_to_char[sample_y.item()])\n",
    "print('Rows', len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910b060e-a61f-4a32-9dcd-ba625ebc222c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Maak een rnn model bestaande uit een embedding layer, gru layer en linear layer\n",
    "# Maak het mogelijk om aan de forward funtie een parameter toe te voegen om ook de hidden state terug te geven en om de hidden state mee te geven voor de gru laag\n",
    "# \n",
    "vocab_size = len(idx_to_char)\n",
    "print(vocab_size)\n",
    "embedding_dim = 50\n",
    "rnn_units = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd60acb-29d3-4087-b7a9-8f64b2c9fd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 1 sample om door het model te sturen\n",
    "# kijk of je dimensies correct aan elkaar gekoppeld zijn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fbb345-d9f0-477a-98c2-2aa83db41963",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import math\n",
    "\n",
    "batch_size = 64\n",
    "seq_length = 100\n",
    "epochs = 5\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 50\n",
    "rnn_units = 60\n",
    "\n",
    "shakespeare = ShakespeareModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)\n",
    "\n",
    "# TODO: train het rnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec92677b-7f6b-4cb1-9f6b-faf2da8a68b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def generate_text(model, start_string, char_to_idx, idx_to_char, vocab_size, generation_length=100, temperature=1.0):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    # Convert start_string to indices\n",
    "    input_indices = torch.tensor([char_to_idx[char] for char in start_string], dtype=torch.long).unsqueeze(0)\n",
    "    \n",
    "    generated_text = start_string\n",
    "    states = None  # Initial state (None means it will be initialized automatically)\n",
    "    \n",
    "    for _ in range(generation_length):\n",
    "        # Genereer opeenvolgend nieuwe tokens\n",
    "        pass\n",
    "    \n",
    "    return generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d49248-9fad-4174-a5a1-af319bcfc38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example start string and generation parameters\n",
    "start_string = \"ROMEO: \"\n",
    "generation_length = 200\n",
    "temperature = 0.8\n",
    "\n",
    "# Generate text\n",
    "generated_text = generate_text(\n",
    "    model=shakespeare,\n",
    "    start_string=start_string,\n",
    "    char_to_idx=char_to_idx,\n",
    "    idx_to_char=idx_to_char,\n",
    "    vocab_size=vocab_size,\n",
    "    generation_length=generation_length,\n",
    "    temperature=temperature\n",
    ")\n",
    "\n",
    "print(\"Generated Text:\")\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645098d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5489145",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
