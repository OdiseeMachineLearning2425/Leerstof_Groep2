{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ece9ec2a-8afa-4f7f-bfe9-0609d1100f6b",
   "metadata": {},
   "source": [
    "# Classificatie van nieuwsartikelen\n",
    "\n",
    "In deze notebook gaan we verder werken op de AG-news nieuwsartikelen dataset.\n",
    "In de vorige notebook hebben we bekeken hoe we tekstuele data kunnen preprocessen.\n",
    "In deze notebook gaan we classificatie uitvoeren door gebruik te maken van recurrente neurale netwerken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1342a98-3aa7-4c0c-96d5-f39fa70db39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \"./ag-news-classification-dataset\" (use force=True to force download)\n",
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              title  \\\n",
       "0      2  Wall St. Bears Claw Back Into the Black (Reuters)   \n",
       "1      2  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
       "2      2    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
       "3      2  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
       "4      2  Oil prices soar to all-time record, posing new...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Reuters - Short-sellers, Wall Street's dwindli...   \n",
       "1  Reuters - Private investment firm Carlyle Grou...   \n",
       "2  Reuters - Soaring crude prices plus worries\\ab...   \n",
       "3  Reuters - Authorities have halted oil export\\f...   \n",
       "4  AFP - Tearaway world oil prices, toppling reco...   \n",
       "\n",
       "                                                text  \n",
       "0  Wall St. Bears Claw Back Into the Black (Reute...  \n",
       "1  Carlyle Looks Toward Commercial Aerospace (Reu...  \n",
       "2  Oil and Economy Cloud Stocks' Outlook (Reuters...  \n",
       "3  Iraq Halts Oil Exports from Main Southern Pipe...  \n",
       "4  Oil prices soar to all-time record, posing new...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from keras_preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import opendatasets as od\n",
    "\n",
    "\n",
    "od.download(\"https://www.kaggle.com/datasets/amananandrai/ag-news-classification-dataset\")\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the dataset\n",
    "def read_csv(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    df.columns = [\"label\", \"title\", \"description\"]\n",
    "    df[\"text\"] = df['title'] + ' ' + df['description']\n",
    "    df['label'] = df['label'] - 1\n",
    "    return df\n",
    "\n",
    "df_train = read_csv('./ag-news-classification-dataset/train.csv')\n",
    "display(df_train.head())\n",
    "\n",
    "df_test = read_csv('./ag-news-classification-dataset/test.csv')\n",
    "\n",
    "# Parameters\n",
    "MAX_NUM_WORDS = 20000  # Maximum number of unique words to keep\n",
    "MAX_SEQUENCE_LENGTH = 50  # Maximum length of input sequences\n",
    "EMBEDDING_DIM = 32  # Dimensionality of the embedding layer\n",
    "\n",
    "# Tokenizer\n",
    "def preprocess(df, tokenizer=None):\n",
    "    if tokenizer is None:\n",
    "        tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "        tokenizer.fit_on_texts(df['text'])\n",
    "        \n",
    "    sequences = tokenizer.texts_to_sequences(df['text'])\n",
    "    X = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "    # Labels (one-hot encoding)\n",
    "    y = to_categorical(df['label'], num_classes=4)\n",
    "\n",
    "    return X, y, tokenizer\n",
    "\n",
    "X_train, y_train, tokenizer = preprocess(df_train)\n",
    "X_test, y_test, _ = preprocess(df_test, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a915b69-e536-4ee0-ac4e-18f19e315734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train)) # X_train is een numpy array, kan perfect gebruikt worden in de analoge functies van pytorch\n",
    "\n",
    "# Dataset + dataloader\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.texts[idx], dtype=torch.long), torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "\n",
    "train_dataset = TextDataset(X_train, y_train)\n",
    "test_dataset = TextDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False) # shuffle false -> niet trainen dus maar 1 epoch dus is shuffle niet belangrijk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdd6c70-ace6-4e59-8973-b6a60f61fadf",
   "metadata": {},
   "source": [
    "## Opbouwen, trainen en evalueren van een RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27421e68-ef48-4718-abe1-3027f8ca22ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNModel(\n",
      "  (embedding): Embedding(20000, 32)\n",
      "  (rnn): RNN(32, 128, batch_first=True)\n",
      "  (fc): Linear(in_features=128, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# RNN model\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim) # bereken de embedding\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True) # verwerk de sequentie (of nn.LSTM of nn.GRU)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim) # bereken output uit de rnn-laag\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, hidden = self.rnn(x) # voer de recurrente laag uit\n",
    "        # geen activatiefunctie hier want we werken enkel met de hidden -> die heeft reeds een tanh uitgevoerd\n",
    "        hidden = hidden.squeeze(0) # laat de eerste dimensie weg\n",
    "        x = self.fc(hidden) # hidden state van de laatste tijdstap gebruiken voor classficatie\n",
    "        return x, hidden\n",
    "\n",
    "hidden_dim = 128\n",
    "output_dim = 4\n",
    "\n",
    "model = RNNModel(MAX_NUM_WORDS, EMBEDDING_DIM, 128, 4)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f42d140-adcb-427d-9c6e-bae79959f052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 50])\n",
      "torch.Size([64, 4]) torch.Size([64, 128])\n"
     ]
    }
   ],
   "source": [
    "for features,label in train_loader:\n",
    "    print(features.shape) # (batch_size, sequence_length)\n",
    "    x, hidden = model(features)\n",
    "    print(x.shape, hidden.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "004d3d31-8d41-4c05-9bfb-fb3b16724f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: loss 0.9162078396002452\n",
      "Epoch 2/5: loss 0.6060804185390473\n",
      "Epoch 3/5: loss 0.4600883013486862\n",
      "Epoch 4/5: loss 0.3739034271876017\n",
      "Epoch 5/5: loss 0.38062629988193514\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Train het Model\n",
    "criterion = nn.CrossEntropyLoss() # dit moet je nog kunnen beantwoorden voor de tweede type A evaluatie\n",
    "# hier cross entropy want multi-class classification probleem\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 5\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs, _ = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}: loss {running_loss/len(train_loader)}\")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9eb57af5-0ff0-499f-94be-35e7e5ea89e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.72368421052632\n"
     ]
    }
   ],
   "source": [
    "# Evalueer het Model\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        \n",
    "        _, labels = torch.max(labels, 1) # labels heeft shape (64, 4) -> zoek per input in de batch naar de grootste klasse\n",
    "        outputs, _ = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1) # torch.max geeft   max, argmax\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy: {100* correct/total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6277e4fc-e559-4f43-8d88-1840cc31dc52",
   "metadata": {},
   "source": [
    "## Oefeningen\n",
    "\n",
    "* Voeg een extra Linear-laag toe na de RNN-laag. Experimenteer met het aantal neuronen in deze laag en analyseer hoe de prestaties veranderen.\n",
    "* Pas het model aan om in plaats van een SimpleRNN-laag een LSTM of GRU-laag te gebruiken. Vergelijk de prestaties van de drie typen recurrente netwerken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8991aec0-9549-4d1b-99fb-897d2331fb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oefening 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7775c80b-0838-4a41-848a-25c499141be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oefening 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0a7182-6e98-40a4-953d-3051cb8687a9",
   "metadata": {},
   "source": [
    "**Oefening 3**\n",
    "\n",
    "Volg de tutorial op de volgende link: https://www.tensorflow.org/text/tutorials/text_generation\n",
    "Werk hieronder het gelijkaardige probleem uit maar maak het door gebruik te maken van pytorch in plaats van tensorflow voor het model op te bouwen.\n",
    "In deze tutorial wordt er tekst gegenereerd die lijkt op tekst geschreven door shakespeare.\n",
    "Let op dat dit een vereenvoudigde versie is waarbij karakter per karakter wordt gegenereerd en niet woord per woord. Er is dus geen garantie dat er echte woorden gemaakt worden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edab02f2-fa9f-4306-8ad2-a378b45eb9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import random\n",
    "\n",
    "path_to_file = keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "print(f'Length of text: {len(text)} characters')\n",
    "print(text[:250])\n",
    "# The unique characters in the file\n",
    "vocab = sorted(set(text))\n",
    "print(f'{len(vocab)} unique characters')\n",
    "\n",
    "# Character to index mapping\n",
    "char_to_idx = {char: idx for idx, char in enumerate(vocab)}\n",
    "idx_to_char = {idx: char for idx, char in enumerate(vocab)}\n",
    "\n",
    "# TODO: Encodeer elk karakter in tekst naar een nummer, uitkomst is een list ipv een string\n",
    "\n",
    "# TODO: Maak een dataset aan waarbij de tekst (uit voorgaande todo) omzet naar een reeks sequenties\n",
    "# input 100 aaneensluitende karakters, output is het karakter erop volgende\n",
    "\n",
    "# TODO: indien nodig maak een subset tot 10 of 1% van de dataset\n",
    "\n",
    "# Check a single example\n",
    "sample_x, sample_y = dataset[0]\n",
    "print(\"Input (x):\", sample_x)\n",
    "print(\"Target (y):\", sample_y)\n",
    "print(\"Decoded Input:\", ''.join(idx_to_char[idx] for idx in sample_x.numpy()))\n",
    "print(\"Decoded Target:\", idx_to_char[sample_y.item()])\n",
    "print('Rows', len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910b060e-a61f-4a32-9dcd-ba625ebc222c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Maak een rnn model bestaande uit een embedding layer, gru layer en linear layer\n",
    "# Maak het mogelijk om aan de forward funtie een parameter toe te voegen om ook de hidden state terug te geven en om de hidden state mee te geven voor de gru laag\n",
    "# \n",
    "vocab_size = len(idx_to_char)\n",
    "print(vocab_size)\n",
    "embedding_dim = 50\n",
    "rnn_units = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd60acb-29d3-4087-b7a9-8f64b2c9fd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 1 sample om door het model te sturen\n",
    "# kijk of je dimensies correct aan elkaar gekoppeld zijn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fbb345-d9f0-477a-98c2-2aa83db41963",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import math\n",
    "\n",
    "batch_size = 64\n",
    "seq_length = 100\n",
    "epochs = 5\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 50\n",
    "rnn_units = 60\n",
    "\n",
    "shakespeare = ShakespeareModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)\n",
    "\n",
    "# TODO: train het rnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec92677b-7f6b-4cb1-9f6b-faf2da8a68b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def generate_text(model, start_string, char_to_idx, idx_to_char, vocab_size, generation_length=100, temperature=1.0):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    # Convert start_string to indices\n",
    "    input_indices = torch.tensor([char_to_idx[char] for char in start_string], dtype=torch.long).unsqueeze(0)\n",
    "    \n",
    "    generated_text = start_string\n",
    "    states = None  # Initial state (None means it will be initialized automatically)\n",
    "    \n",
    "    for _ in range(generation_length):\n",
    "        # Genereer opeenvolgend nieuwe tokens\n",
    "        pass\n",
    "    \n",
    "    return generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d49248-9fad-4174-a5a1-af319bcfc38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example start string and generation parameters\n",
    "start_string = \"ROMEO: \"\n",
    "generation_length = 200\n",
    "temperature = 0.8\n",
    "\n",
    "# Generate text\n",
    "generated_text = generate_text(\n",
    "    model=shakespeare,\n",
    "    start_string=start_string,\n",
    "    char_to_idx=char_to_idx,\n",
    "    idx_to_char=idx_to_char,\n",
    "    vocab_size=vocab_size,\n",
    "    generation_length=generation_length,\n",
    "    temperature=temperature\n",
    ")\n",
    "\n",
    "print(\"Generated Text:\")\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645098d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5489145",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
