{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ece9ec2a-8afa-4f7f-bfe9-0609d1100f6b",
   "metadata": {},
   "source": [
    "# Classificatie van nieuwsartikelen\n",
    "\n",
    "In deze notebook gaan we verder werken op de AG-news nieuwsartikelen dataset.\n",
    "In de vorige notebook hebben we bekeken hoe we tekstuele data kunnen preprocessen.\n",
    "In deze notebook gaan we classificatie uitvoeren door gebruik te maken van recurrente neurale netwerken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1342a98-3aa7-4c0c-96d5-f39fa70db39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \"./ag-news-classification-dataset\" (use force=True to force download)\n",
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              title  \\\n",
       "0      2  Wall St. Bears Claw Back Into the Black (Reuters)   \n",
       "1      2  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
       "2      2    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
       "3      2  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
       "4      2  Oil prices soar to all-time record, posing new...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Reuters - Short-sellers, Wall Street's dwindli...   \n",
       "1  Reuters - Private investment firm Carlyle Grou...   \n",
       "2  Reuters - Soaring crude prices plus worries\\ab...   \n",
       "3  Reuters - Authorities have halted oil export\\f...   \n",
       "4  AFP - Tearaway world oil prices, toppling reco...   \n",
       "\n",
       "                                                text  \n",
       "0  Wall St. Bears Claw Back Into the Black (Reute...  \n",
       "1  Carlyle Looks Toward Commercial Aerospace (Reu...  \n",
       "2  Oil and Economy Cloud Stocks' Outlook (Reuters...  \n",
       "3  Iraq Halts Oil Exports from Main Southern Pipe...  \n",
       "4  Oil prices soar to all-time record, posing new...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from keras_preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import opendatasets as od\n",
    "\n",
    "\n",
    "od.download(\"https://www.kaggle.com/datasets/amananandrai/ag-news-classification-dataset\")\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the dataset\n",
    "def read_csv(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    df.columns = [\"label\", \"title\", \"description\"]\n",
    "    df[\"text\"] = df['title'] + ' ' + df['description']\n",
    "    df['label'] = df['label'] - 1\n",
    "    return df\n",
    "\n",
    "df_train = read_csv('./ag-news-classification-dataset/train.csv')\n",
    "display(df_train.head())\n",
    "\n",
    "df_test = read_csv('./ag-news-classification-dataset/test.csv')\n",
    "\n",
    "# Parameters\n",
    "MAX_NUM_WORDS = 20000  # Maximum number of unique words to keep\n",
    "MAX_SEQUENCE_LENGTH = 50  # Maximum length of input sequences\n",
    "EMBEDDING_DIM = 32  # Dimensionality of the embedding layer\n",
    "\n",
    "# Tokenizer\n",
    "def preprocess(df, tokenizer=None):\n",
    "    if tokenizer is None:\n",
    "        tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "        tokenizer.fit_on_texts(df['text'])\n",
    "        \n",
    "    sequences = tokenizer.texts_to_sequences(df['text'])\n",
    "    X = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "    # Labels (one-hot encoding)\n",
    "    y = to_categorical(df['label'], num_classes=4)\n",
    "\n",
    "    return X, y, tokenizer\n",
    "\n",
    "X_train, y_train, tokenizer = preprocess(df_train)\n",
    "X_test, y_test, _ = preprocess(df_test, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a915b69-e536-4ee0-ac4e-18f19e315734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train)) # X_train is een numpy array, kan perfect gebruikt worden in de analoge functies van pytorch\n",
    "\n",
    "# Dataset + dataloader\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.texts[idx], dtype=torch.long), torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "\n",
    "train_dataset = TextDataset(X_train, y_train)\n",
    "test_dataset = TextDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False) # shuffle false -> niet trainen dus maar 1 epoch dus is shuffle niet belangrijk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdd6c70-ace6-4e59-8973-b6a60f61fadf",
   "metadata": {},
   "source": [
    "## Opbouwen, trainen en evalueren van een RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27421e68-ef48-4718-abe1-3027f8ca22ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNModel(\n",
      "  (embedding): Embedding(20000, 32)\n",
      "  (rnn): RNN(32, 128, batch_first=True)\n",
      "  (fc): Linear(in_features=128, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# RNN model\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim) # bereken de embedding\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True) # verwerk de sequentie (of nn.LSTM of nn.GRU)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim) # bereken output uit de rnn-laag\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, hidden = self.rnn(x) # voer de recurrente laag uit\n",
    "        # geen activatiefunctie hier want we werken enkel met de hidden -> die heeft reeds een tanh uitgevoerd\n",
    "        hidden = hidden.squeeze(0) # laat de eerste dimensie weg\n",
    "        x = self.fc(hidden) # hidden state van de laatste tijdstap gebruiken voor classficatie\n",
    "        return x, hidden\n",
    "\n",
    "hidden_dim = 128\n",
    "output_dim = 4\n",
    "\n",
    "model = RNNModel(MAX_NUM_WORDS, EMBEDDING_DIM, 128, 4)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f42d140-adcb-427d-9c6e-bae79959f052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 50])\n",
      "torch.Size([64, 4]) torch.Size([64, 128])\n"
     ]
    }
   ],
   "source": [
    "for features,label in train_loader:\n",
    "    print(features.shape) # (batch_size, sequence_length)\n",
    "    x, hidden = model(features)\n",
    "    print(x.shape, hidden.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "004d3d31-8d41-4c05-9bfb-fb3b16724f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: loss 0.9162078396002452\n",
      "Epoch 2/5: loss 0.6060804185390473\n",
      "Epoch 3/5: loss 0.4600883013486862\n",
      "Epoch 4/5: loss 0.3739034271876017\n",
      "Epoch 5/5: loss 0.38062629988193514\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Train het Model\n",
    "criterion = nn.CrossEntropyLoss() # dit moet je nog kunnen beantwoorden voor de tweede type A evaluatie\n",
    "# hier cross entropy want multi-class classification probleem\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 5\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs, _ = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}: loss {running_loss/len(train_loader)}\")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9eb57af5-0ff0-499f-94be-35e7e5ea89e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.72368421052632\n"
     ]
    }
   ],
   "source": [
    "# Evalueer het Model\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        \n",
    "        _, labels = torch.max(labels, 1) # labels heeft shape (64, 4) -> zoek per input in de batch naar de grootste klasse\n",
    "        outputs, _ = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1) # torch.max geeft   max, argmax\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy: {100* correct/total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6277e4fc-e559-4f43-8d88-1840cc31dc52",
   "metadata": {},
   "source": [
    "## Oefeningen\n",
    "\n",
    "* Voeg een extra Linear-laag toe na de RNN-laag. Experimenteer met het aantal neuronen in deze laag en analyseer hoe de prestaties veranderen.\n",
    "* Pas het model aan om in plaats van een SimpleRNN-laag een LSTM of GRU-laag te gebruiken. Vergelijk de prestaties van de drie typen recurrente netwerken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8991aec0-9549-4d1b-99fb-897d2331fb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oefening 1\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim) # bereken de embedding\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True) # verwerk de sequentie (of nn.LSTM of nn.GRU)\n",
    "        self.fc = nn.Linear(hidden_dim, 16) # bereken output uit de rnn-laag\n",
    "        self.fc2 = nn.Linear(16, output_dim) # bereken output uit de rnn-laag\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, hidden = self.rnn(x) # voer de recurrente laag uit\n",
    "        # geen activatiefunctie hier want we werken enkel met de hidden -> die heeft reeds een tanh uitgevoerd\n",
    "        hidden = hidden.squeeze(0) # laat de eerste dimensie weg\n",
    "        x = nn.functional.relu(self.fc(hidden)) # hidden state van de laatste tijdstap gebruiken voor classficatie\n",
    "        x = self.fc2(x)\n",
    "        return x, hidden\n",
    "\n",
    "# fc2 toegevoegd\n",
    "# we hebben ervoor gekozen om fc 16 neuronen breed te maken\n",
    "# fc2 bevat 4 neuronen\n",
    "# activatiefunctie toegevoegd in de forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7775c80b-0838-4a41-848a-25c499141be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: loss 0.6616245873530706\n",
      "Epoch 2/5: loss 0.34016635310649873\n",
      "Epoch 3/5: loss 0.2685256950259209\n",
      "Epoch 4/5: loss 0.22716335246960323\n",
      "Epoch 5/5: loss 0.19350809991161028\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Oefening 2\n",
    "\n",
    "class RNNModel2(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(RNNModel2, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim) # bereken de embedding\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, batch_first=True) # verwerk de sequentie (of nn.LSTM of nn.GRU)\n",
    "        self.fc = nn.Linear(hidden_dim, 16) # bereken output uit de rnn-laag\n",
    "        self.fc2 = nn.Linear(16, output_dim) # bereken output uit de rnn-laag\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, (hidden, _) = self.rnn(x) # voer de recurrente laag uit\n",
    "        # geen activatiefunctie hier want we werken enkel met de hidden -> die heeft reeds een tanh uitgevoerd\n",
    "        hidden = hidden.squeeze(0) # laat de eerste dimensie weg\n",
    "        x = nn.functional.relu(self.fc(hidden)) # hidden state van de laatste tijdstap gebruiken voor classficatie\n",
    "        x = self.fc2(x)\n",
    "        return x, hidden\n",
    "\n",
    "\n",
    "model = RNNModel2(MAX_NUM_WORDS, EMBEDDING_DIM, 128, 4)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # dit moet je nog kunnen beantwoorden voor de tweede type A evaluatie\n",
    "# hier cross entropy want multi-class classification probleem\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 5\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs, _ = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}: loss {running_loss/len(train_loader)}\")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0a7182-6e98-40a4-953d-3051cb8687a9",
   "metadata": {},
   "source": [
    "**Oefening 3**\n",
    "\n",
    "Volg de tutorial op de volgende link: https://www.tensorflow.org/text/tutorials/text_generation\n",
    "Werk hieronder het gelijkaardige probleem uit maar maak het door gebruik te maken van pytorch in plaats van tensorflow voor het model op te bouwen.\n",
    "In deze tutorial wordt er tekst gegenereerd die lijkt op tekst geschreven door shakespeare.\n",
    "Let op dat dit een vereenvoudigde versie is waarbij karakter per karakter wordt gegenereerd en niet woord per woord. Er is dus geen garantie dat er echte woorden gemaakt worden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "edab02f2-fa9f-4306-8ad2-a378b45eb9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 1115394 characters\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "65 unique characters\n",
      "[18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 14, 43, 44, 53, 56, 43, 1, 61, 43, 1, 54, 56, 53, 41, 43, 43, 42, 1, 39, 52, 63, 1, 44, 59, 56, 58, 46, 43, 56, 6, 1, 46, 43, 39, 56, 1, 51, 43, 1, 57, 54, 43, 39, 49, 8, 0, 0, 13, 50, 50, 10, 0, 31, 54, 43, 39, 49, 6, 1, 57, 54, 43, 39, 49, 8, 0, 0, 18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 37, 53, 59, 1, 39, 56, 43, 1, 39, 50, 50, 1, 56, 43, 57, 53, 50, 60, 43, 42, 1, 56, 39, 58, 46, 43, 56, 1, 58, 53, 1, 42, 47, 43, 1, 58, 46, 39, 52, 1, 58, 53, 1, 44, 39, 51, 47, 57, 46, 12, 0, 0, 13, 50, 50, 10, 0, 30, 43, 57, 53, 50, 60, 43, 42, 8, 1, 56, 43, 57, 53, 50, 60, 43, 42, 8, 0, 0, 18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 18, 47, 56, 57, 58, 6, 1, 63, 53, 59, 1, 49, 52, 53, 61, 1, 15, 39, 47, 59, 57, 1, 25, 39, 56, 41, 47, 59, 57, 1, 47, 57, 1, 41, 46, 47, 43, 44, 1, 43, 52, 43, 51, 63, 1, 58, 53, 1, 58, 46, 43, 1, 54, 43, 53, 54, 50, 43, 8, 0]\n",
      "Input (x): tensor([46,  6,  1, 61, 46, 39, 58,  1, 39, 52,  1, 59, 52, 49, 47, 52, 42,  1,\n",
      "        46, 53, 59, 56,  0, 21, 57,  1, 45, 59, 47, 50, 58, 63,  1, 53, 44,  1,\n",
      "        58, 46, 47, 57,  1, 50, 39, 51, 43, 52, 58, 39, 40, 50, 43,  1, 41, 46,\n",
      "        39, 52, 41, 43,  2,  0, 32, 46, 43,  1, 50, 39, 42, 63,  1, 57, 58, 47,\n",
      "        56, 57,  8,  0,  0, 22, 33, 24, 21, 17, 32, 10,  0, 27,  1, 41, 53, 51,\n",
      "        44, 53, 56, 58, 39, 40, 50, 43,  1, 44])\n",
      "Target (y): tensor(56.)\n",
      "Decoded Input: h, what an unkind hour\n",
      "Is guilty of this lamentable chance!\n",
      "The lady stirs.\n",
      "\n",
      "JULIET:\n",
      "O comfortable f\n",
      "Decoded Target: r\n",
      "Rows 11152\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import random\n",
    "\n",
    "path_to_file = keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "print(f'Length of text: {len(text)} characters')\n",
    "print(text[:250])\n",
    "# The unique characters in the file\n",
    "vocab = sorted(set(text))\n",
    "print(f'{len(vocab)} unique characters')\n",
    "\n",
    "# Character to index mapping\n",
    "char_to_idx = {char: idx for idx, char in enumerate(vocab)}\n",
    "idx_to_char = {idx: char for idx, char in enumerate(vocab)}\n",
    "\n",
    "# TODO: Encodeer elk karakter in tekst naar een nummer, uitkomst is een list ipv een string\n",
    "encoded_text = [char_to_idx[char] for char in text] \n",
    "print(encoded_text[:250])\n",
    "\n",
    "# TODO: Maak een dataset aan waarbij de tekst (uit voorgaande todo) omzet naar een reeks sequenties\n",
    "# input 100 aaneensluitende karakters, output is het karakter erop volgende\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text, seq_length):\n",
    "        self.text = text\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text) - self.seq_length # zodat we niet in de laatste karakters kijken -> we kunnen geen volledige sequentie maken\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.text[idx:idx+self.seq_length]\n",
    "        y = self.text[idx+self.seq_length]\n",
    "        \n",
    "        return torch.tensor(x, dtype=torch.long), torch.tensor(y, dtype=torch.float)\n",
    "\n",
    "seq_length = 100\n",
    "dataset = TextDataset(encoded_text, seq_length)\n",
    "\n",
    "# TODO: indien nodig maak een subset tot 10 of 1% van de dataset\n",
    "subset_size=int(0.01 * len(dataset))\n",
    "random_indices = random.sample(range(len(dataset)), subset_size) # selecteer 1% examples/inputs\n",
    "dataset = Subset(dataset, random_indices)\n",
    "\n",
    "# Check a single example\n",
    "sample_x, sample_y = dataset[0]\n",
    "print(\"Input (x):\", sample_x)\n",
    "print(\"Target (y):\", sample_y)\n",
    "print(\"Decoded Input:\", ''.join(idx_to_char[idx] for idx in sample_x.numpy()))\n",
    "print(\"Decoded Target:\", idx_to_char[sample_y.item()])\n",
    "print('Rows', len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "910b060e-a61f-4a32-9dcd-ba625ebc222c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n"
     ]
    }
   ],
   "source": [
    "# TODO: Maak een rnn model bestaande uit een embedding layer, gru layer en linear layer\n",
    "# Maak het mogelijk om aan de forward funtie een parameter toe te voegen om ook de hidden state terug te geven en om de hidden state mee te geven voor de gru laag\n",
    "# \n",
    "vocab_size = len(idx_to_char)\n",
    "print(vocab_size)\n",
    "embedding_dim = 50\n",
    "rnn_units = 60\n",
    "\n",
    "class ShakespeareModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(ShakespeareModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim) # bereken de embedding\n",
    "        self.rnn = nn.GRU(embedding_dim, hidden_dim, batch_first=True) # verwerk de sequentie (of nn.LSTM of nn.GRU)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size) # bereken output uit de rnn-laag\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        x = self.embedding(x)\n",
    "        if hidden is None:\n",
    "            x, hidden = self.rnn(x) # voer de recurrente laag uit\n",
    "        else:\n",
    "            x, hidden = self.rnn(x, hidden)\n",
    "        x = self.fc(hidden.squeeze(0)) # hidden state van de laatste tijdstap gebruiken voor classficatie\n",
    "        return x, hidden\n",
    "\n",
    "shakespeare = ShakespeareModel(vocab_size, embedding_dim, rnn_units)\n",
    "\n",
    "# RNN vervangen door GRU\n",
    "# output_dim = vocab_size\n",
    "# in de forward functie de hidden meegeven met de GRU-laag\n",
    "# de squeeze niet uitvoeren op de hidden die in de return zit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4cd60acb-29d3-4087-b7a9-8f64b2c9fd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100])\n",
      "torch.Size([1, 65]) # (sequence_length, vocab_size), 100 char as input\n"
     ]
    }
   ],
   "source": [
    "# test 1 sample om door het model te sturen\n",
    "# kijk of je dimensies correct aan elkaar gekoppeld zijn\n",
    "for input_example_batch, target_example_batch in dataset:\n",
    "    print(input_example_batch.shape)\n",
    "    example_batch_predictions, _ = shakespeare(input_example_batch.unsqueeze(0))\n",
    "    print(example_batch_predictions.shape, \"# (sequence_length, vocab_size), 100 char as input\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "45fbb345-d9f0-477a-98c2-2aa83db41963",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing model...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ShakespeareModel:\n\tMissing key(s) in state_dict: \"rnn.weight_ih_l0\", \"rnn.weight_hh_l0\", \"rnn.bias_ih_l0\", \"rnn.bias_hh_l0\", \"fc.weight\", \"fc.bias\". \n\tUnexpected key(s) in state_dict: \"gru.weight_ih_l0\", \"gru.weight_hh_l0\", \"gru.bias_ih_l0\", \"gru.bias_hh_l0\", \"output.weight\", \"output.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(model_path):\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading existing model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 30\u001b[0m     \u001b[43mshakespeare\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     shakespeare\u001b[38;5;241m.\u001b[39meval()  \u001b[38;5;66;03m# Set model to evaluation mode if only inference is required\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# Training loop\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:2153\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2149\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2150\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2154\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ShakespeareModel:\n\tMissing key(s) in state_dict: \"rnn.weight_ih_l0\", \"rnn.weight_hh_l0\", \"rnn.bias_ih_l0\", \"rnn.bias_hh_l0\", \"fc.weight\", \"fc.bias\". \n\tUnexpected key(s) in state_dict: \"gru.weight_ih_l0\", \"gru.weight_hh_l0\", \"gru.bias_ih_l0\", \"gru.bias_hh_l0\", \"output.weight\", \"output.bias\". "
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import math\n",
    "\n",
    "batch_size = 64\n",
    "seq_length = 100\n",
    "epochs = 5\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 50\n",
    "rnn_units = 60\n",
    "\n",
    "shakespeare = ShakespeareModel(\n",
    "    vocab_size,\n",
    "    embedding_dim,\n",
    "    rnn_units)\n",
    "\n",
    "# TODO: train het rnn model\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(shakespeare.parameters(), lr=0.001)\n",
    "\n",
    "# Set the path to save/load the model\n",
    "model_path = \"rnns.pth\"\n",
    "\n",
    "# Check if the model file exists\n",
    "if os.path.exists(model_path):\n",
    "    print(\"Loading existing model...\")\n",
    "    shakespeare.load_state_dict(torch.load(model_path))\n",
    "    shakespeare.eval()  # Set model to evaluation mode if only inference is required\n",
    "else:\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        shakespeare.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch, (inputs, targets) in enumerate(dataloader):\n",
    "            # Zero the gradient\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = shakespeare(inputs)  # Shape: (batch_size, seq_length, vocab_size)\n",
    "            \n",
    "            # Reshape outputs and targets for loss computation\n",
    "            outputs = outputs.view(-1, vocab_size)  # Shape: (batch_size * seq_length, vocab_size)\n",
    "            targets = targets.view(-1)  # Shape: (batch_size * seq_length)\n",
    "            \n",
    "            # Compute the loss\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "\n",
    "            if batch % int((len(dataloader)/10)) == 0:\n",
    "                print(f\"Epoch {epoch + 1}/{epochs}: {math.floor(batch/len(dataloader)*100)}\")\n",
    "        \n",
    "        # Print epoch loss\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {avg_loss:.4f}%\")\n",
    "    \n",
    "    # Save the model after training\n",
    "    torch.save(shakespeare.state_dict(), model_path)\n",
    "    print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec92677b-7f6b-4cb1-9f6b-faf2da8a68b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def generate_text(model, start_string, char_to_idx, idx_to_char, vocab_size, generation_length=100, temperature=1.0):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    # Convert start_string to indices\n",
    "    input_indices = torch.tensor([char_to_idx[char] for char in start_string], dtype=torch.long).unsqueeze(0)\n",
    "    \n",
    "    generated_text = start_string\n",
    "    states = None  # Initial state (None means it will be initialized automatically)\n",
    "    \n",
    "    for _ in range(generation_length):\n",
    "        # Genereer opeenvolgend nieuwe tokens\n",
    "        with torch.no_grad():\n",
    "            outputs, states = model(input_indices, states)\n",
    "\n",
    "        logits = outputs\n",
    "        logits = logits/temperature\n",
    "\n",
    "        probabilities = F.softmax(logits, dim=1) # bepaal de kans voor elk karakter\n",
    "        next_index = torch.multinomial(proabilities, num_samples=1).item() # neem 1 karaketer op basis van bovenstaande kansen\n",
    "\n",
    "        generated_text += idx_to_char[next_index]\n",
    "        input_indices = torch.tensor([[next_index]], dtype=torch.long)\n",
    "    \n",
    "    return generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d49248-9fad-4174-a5a1-af319bcfc38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example start string and generation parameters\n",
    "start_string = \"ROMEO: \"\n",
    "generation_length = 200\n",
    "temperature = 0.8\n",
    "\n",
    "# Generate text\n",
    "generated_text = generate_text(\n",
    "    model=shakespeare,\n",
    "    start_string=start_string,\n",
    "    char_to_idx=char_to_idx,\n",
    "    idx_to_char=idx_to_char,\n",
    "    vocab_size=vocab_size,\n",
    "    generation_length=generation_length,\n",
    "    temperature=temperature\n",
    ")\n",
    "\n",
    "print(\"Generated Text:\")\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645098d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5489145",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
