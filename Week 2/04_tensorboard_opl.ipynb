{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6115b825-02b4-479f-b443-fe1ac68e76e9",
   "metadata": {},
   "source": [
    "# Tensorboard\n",
    "\n",
    "Hieronder staan twee voorbeelden van hoe tensorboard kan gebruikt worden met pytroch en tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d9efa3a-a1d4-4f13-99a6-1e3201c44406",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-26 10:23:00.246120: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-26 10:23:00.256293: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-26 10:23:00.268434: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-26 10:23:00.272269: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-26 10:23:00.281891: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-26 10:23:01.469353: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Maak een SummaryWriter aan\n",
    "writer = SummaryWriter('runs/my_first_run')\n",
    "\n",
    "# Genereer dummy data\n",
    "X = torch.randn(100, 10)  # 100 samples, 10 features\n",
    "y = torch.randn(100, 1)\n",
    "\n",
    "# Definieer het model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(10, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(5, 1)\n",
    ")\n",
    "\n",
    "# Definieer de loss function en optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train het model en log de resultaten naar TensorBoard\n",
    "for epoch in range(10):\n",
    "    # Forward pass\n",
    "    outputs = model(X)\n",
    "    loss = criterion(outputs, y)\n",
    "\n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Log de loss naar TensorBoard\n",
    "    writer.add_scalar('Loss', loss.item(), epoch)\n",
    "\n",
    "# Log de modelgrafiek naar TensorBoard\n",
    "writer.add_graph(model, input_to_model=torch.rand(1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe5c96a-c1da-4ad4-b656-6812a5cb8ae2",
   "metadata": {},
   "source": [
    "Door bovenstaande code uit te voeren wordt een map aangemaakt waar de nodige logs in bewaard worden.\n",
    "Deze kunnen daarna gevisualiseerd worden met behulp van het volgende terminal-commando.\n",
    "In de output van het commando krijg je een url te zien met de link waar je de tensorboard applicatie kan bekijken.\n",
    "Met de standaardconfiguratie van de docker container moet je de applicatie kunnen bereiken via de link [localhost:6006](http://localhost:6006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c63dc7-58fa-441b-bf48-f40bf76ca4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-26 10:23:35.850419: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-26 10:23:35.851448: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-26 10:23:35.853797: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-26 10:23:35.860835: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-26 10:23:35.872110: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-26 10:23:35.875249: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-26 10:23:35.884998: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-26 10:23:36.496797: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1721989417.879155     132 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-26 10:23:37.879539: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1721989417.894637     132 config.cc:230] gRPC experiments enabled: call_status_override_on_cancellation, event_engine_dns, event_engine_listener, http2_stats_fix, monitoring_experiment, pick_first_new, trace_record_callops, work_serializer_clears_time_cache\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "TensorBoard 2.17.0 at http://2f97cef0a7bc:6006/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=runs --bind_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5f8374-27dc-4071-8b21-ee722051be8c",
   "metadata": {},
   "source": [
    "De manier om het met tensorflow uit te voeren is in principe analoog.\n",
    "Omdat bij tensorflow de training-loop achter de schermen uitgevoerd wordt, moet er echter een callback toegevoegd worden.\n",
    "Dit kan gebruikt worden om het trainingsprocess te manipuleren bij Tensorflow/Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e837ee-de59-4d6d-92b8-716144f51493",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
