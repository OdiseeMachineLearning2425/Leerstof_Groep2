{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zwBCE43Cv3PH"
   },
   "source": [
    "# Gestructureerde data: preprocessing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In dit voorbeeld gaan we verder werken op de titanic dataset bestudeerd in voorgaande notebook.\n",
    "Hierbij gaan we preprocessing toevoegen of in meer detail bespreken.\n",
    "\n",
    "Hierbij is een belangrijk onderscheid tussen pytorch en tensorflow op te merken. Hierbij is het belangrijk om te realiseren dat pytorch verwacht dat alle data dat uit de __get__item functie komt numeriek is. Deze moet niet noodzakelijk reeds geschaald zijn maar moet wel dat datatype hebben. Het is dus belangrijk om een goede keuze te maken op welke plaats de nodige preprocessing stappen uitgevoerd worden. \n",
    "In het geval van tensorflow (in het geval van mixed datatypes) plaatsen we van in het begin elke feature apart. Daarna voegen we gelijkaardige features samen om deze te preprocessen. Pas op het einde van dit proces worden alle features samengevoegd tot een numerieke tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>Second</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>First</td>\n",
       "      <td>B</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>627 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived     sex   age  n_siblings_spouses  parch     fare   class  \\\n",
       "0           0    male  22.0                   1      0   7.2500   Third   \n",
       "1           1  female  38.0                   1      0  71.2833   First   \n",
       "2           1  female  26.0                   0      0   7.9250   Third   \n",
       "3           1  female  35.0                   1      0  53.1000   First   \n",
       "4           0    male  28.0                   0      0   8.4583   Third   \n",
       "..        ...     ...   ...                 ...    ...      ...     ...   \n",
       "622         0    male  28.0                   0      0  10.5000  Second   \n",
       "623         0    male  25.0                   0      0   7.0500   Third   \n",
       "624         1  female  19.0                   0      0  30.0000   First   \n",
       "625         0  female  28.0                   1      2  23.4500   Third   \n",
       "626         0    male  32.0                   0      0   7.7500   Third   \n",
       "\n",
       "        deck  embark_town alone  \n",
       "0    unknown  Southampton     n  \n",
       "1          C    Cherbourg     n  \n",
       "2    unknown  Southampton     y  \n",
       "3          C  Southampton     n  \n",
       "4    unknown   Queenstown     y  \n",
       "..       ...          ...   ...  \n",
       "622  unknown  Southampton     y  \n",
       "623  unknown  Southampton     y  \n",
       "624        B  Southampton     y  \n",
       "625  unknown  Southampton     n  \n",
       "626  unknown   Queenstown     y  \n",
       "\n",
       "[627 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load Titanic dataset\n",
    "titanic = pd.read_csv(\"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")\n",
    "display(titanic)\n",
    "\n",
    "# Define the preprocessing pipeline\n",
    "numeric_features = ['age', 'n_siblings_spouses', 'parch', 'fare']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_features = ['sex', 'class', 'embark_town', 'deck', 'alone']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define custom PyTorch Dataset\n",
    "class TitanicDataset(Dataset):\n",
    "    def __init__(self, dataframe, preprocessor, train=True):\n",
    "        # Separate features and target\n",
    "        self.X = dataframe.drop('survived', axis=1)\n",
    "        \n",
    "        self.preprocessor = preprocessor        \n",
    "        if train:\n",
    "            preprocessor.fit(self.X)\n",
    "        self.X = torch.tensor(preprocessor.transform(self.X), dtype=torch.float32)\n",
    "        \n",
    "        y = dataframe['survived']\n",
    "        self.y = torch.tensor(y.values, dtype=torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Train test\n",
    "titanic_train = titanic.sample(frac=0.8)\n",
    "titanic_test = titanic.drop(titanic_train.index)\n",
    "\n",
    "# Create the dataset\n",
    "dataset_train = TitanicDataset(titanic_train, preprocessor)\n",
    "dataset_test = TitanicDataset(titanic_test, preprocessor, train=False)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(dataset_train, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(dataset_test, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras/Tensorflow\n",
    "\n",
    "Dit stukje is de meest complexe vorm om data in te laden maar misschien ook het meest flexible.\n",
    "We gaan namelijk van een dataset met mixed types een sequentieel model maken waarbij de nodige preprocessing stappen aanwezig zijn in het model.\n",
    "Dit gaat uiteindelijk leiden tot een vrij complexe modelopbouw.\n",
    "\n",
    "Omdat preprocessing functionaliteiten slechts in de volgende stap gaan bestudeerd worden gaan we hier enkel kijken hoe we de data kunnen klaar zetten.\n",
    "De twee methodes hiervoor zijn:\n",
    "* Plaats elke input/feature in een apart Input object. Dit zijn symbolische tensors die gebruikt worden als placeholder voor onze data\n",
    "* Maak een csv dataset (identiek als hierboven)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import Input\n",
    "from keras import layers\n",
    "\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "\n",
    "titanic_features = titanic.copy()\n",
    "titanic_labels = titanic_features.pop('survived')\n",
    "\n",
    "inputs = {}\n",
    "\n",
    "for name, column in titanic_features.items():\n",
    "  dtype = column.dtype\n",
    "  if dtype == object:\n",
    "    dtype = tf.string\n",
    "  else:\n",
    "    dtype = tf.float32\n",
    "\n",
    "  inputs[name] = Input(shape=(1,), name=name, dtype=dtype)\n",
    "\n",
    "inputs\n",
    "\n",
    "# selecteer gelijkaardige inputs\n",
    "numeric_inputs = {name:input for name,input in inputs.items()\n",
    "                  if input.dtype==tf.float32}\n",
    "categoric_inputs = {name:input for name,input in inputs.items()\n",
    "                  if input.dtype==tf.string}\n",
    "\n",
    "# om alle verschillende eindresultaten bij te houden\n",
    "preprocessed_inputs = []\n",
    "\n",
    "# preprocess numeriek\n",
    "x = layers.Concatenate()(list(numeric_inputs.values()))\n",
    "norm = layers.Normalization()\n",
    "norm.adapt(np.array(titanic[numeric_inputs.keys()]))\n",
    "\n",
    "preprocessed_inputs.append(norm(x))\n",
    "\n",
    "# preprocess categoriek\n",
    "for name, input in categoric_inputs.items():\n",
    "  lookup = layers.StringLookup(vocabulary=np.unique(titanic_features[name]))\n",
    "  one_hot = layers.CategoryEncoding(num_tokens=lookup.vocabulary_size())\n",
    "\n",
    "  x = lookup(input)\n",
    "  x = one_hot(x)\n",
    "    \n",
    "  preprocessed_inputs.append(x)\n",
    "\n",
    "# voeg alle verwerkte inputs samen\n",
    "preprocessed_inputs_cat = layers.Concatenate()(preprocessed_inputs)\n",
    "\n",
    "titanic_preprocessing = tf.keras.Model(inputs, preprocessed_inputs_cat)\n",
    "\n",
    "tf.keras.utils.plot_model(model = titanic_preprocessing , rankdir=\"LR\", dpi=72, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oefening: Inkomensdataset\n",
    "\n",
    "Met onderstaande code downloaden we een csv met gegevens rond het inkomen van volwassenen.\n",
    "Plaats in de code-cellen eronder de nodige code om de volgende preprocessingstappen uit te voeren met zowel pytorch als tensorflow:\n",
    "\n",
    "* Splits in train-test\n",
    "* Label kolom is het inkomen -> voer hiervoor ordinal encoding uit\n",
    "* Voer normalisatie uit van de numerieke kolommen zodat alle waarden tussen 0 en 1 liggen (geen standaardverdeling)\n",
    "* Voer ordinal encoding uit op de occupation en native_country kolom\n",
    "* Voer one-hot encoding uit op de overige niet-numerieke kolommen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education_num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital_status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week  native_country  income  \n",
       "0          2174             0              40   United-States   <=50K  \n",
       "1             0             0              13   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  \n",
       "3             0             0              40   United-States   <=50K  \n",
       "4             0             0              40            Cuba   <=50K  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
    "columns = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', \n",
    "           'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', \n",
    "           'hours_per_week', 'native_country', 'income']\n",
    "adult_income = pd.read_csv(url, header=None, names=columns)\n",
    "\n",
    "adult_income.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder, OneHotEncoder\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class AdultIncomeDataset(Dataset):\n",
    "    def __init__(self, data, scaler=None, ordinal_enc=None, onehot_enc=None, train=True):\n",
    "        columns = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', \n",
    "                   'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', \n",
    "                   'hours_per_week', 'native_country', 'income']\n",
    "        \n",
    "        # Load and set up columns\n",
    "        self.data = pd.read_csv(data, header=None, names=columns)\n",
    "        \n",
    "        # Identify the columns\n",
    "        self.numerical_cols = ['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week']\n",
    "        self.ordinal_cols = ['occupation', 'native_country']\n",
    "        self.onehot_cols = ['workclass', 'education', 'marital_status', 'relationship', 'race', 'sex']\n",
    "        \n",
    "        # Ordinal encoding for 'income' (target label)\n",
    "        income_enc = OrdinalEncoder(categories=[[' <=50K', ' >50K']])\n",
    "        self.data['income'] = income_enc.fit_transform(self.data[['income']])\n",
    "\n",
    "        # Normalize numerical columns (MinMaxScaler)\n",
    "        if scaler is None:\n",
    "            self.scaler = MinMaxScaler()\n",
    "            self.data[self.numerical_cols] = self.scaler.fit_transform(self.data[self.numerical_cols])\n",
    "        else:\n",
    "            self.scaler = scaler\n",
    "            self.data[self.numerical_cols] = self.scaler.transform(self.data[self.numerical_cols])\n",
    "        \n",
    "        # Ordinal encoding for specific columns\n",
    "        if ordinal_enc is None:\n",
    "            self.ordinal_enc = OrdinalEncoder()\n",
    "            self.data[self.ordinal_cols] = self.ordinal_enc.fit_transform(self.data[self.ordinal_cols])\n",
    "        else:\n",
    "            self.ordinal_enc = ordinal_enc\n",
    "            self.data[self.ordinal_cols] = self.ordinal_enc.transform(self.data[self.ordinal_cols])\n",
    "        \n",
    "        # One-hot encoding for categorical columns\n",
    "        if onehot_enc is None:\n",
    "            self.onehot_enc = OneHotEncoder(sparse=False, drop='first')\n",
    "            onehot_encoded = self.onehot_enc.fit_transform(self.data[self.onehot_cols])\n",
    "        else:\n",
    "            self.onehot_enc = onehot_enc\n",
    "            onehot_encoded = self.onehot_enc.transform(self.data[self.onehot_cols])\n",
    "        \n",
    "        # Combine data\n",
    "        self.data = pd.concat([self.data.drop(columns=self.onehot_cols), \n",
    "                               pd.DataFrame(onehot_encoded, index=self.data.index)], axis=1)\n",
    "        \n",
    "        # Separate features and labels\n",
    "        self.X = self.data.drop(columns='income').values\n",
    "        self.y = self.data['income'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = torch.tensor(self.X[idx], dtype=torch.float32)\n",
    "        y = torch.tensor(self.y[idx], dtype=torch.float32)\n",
    "        return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "pandas_dataframe.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
