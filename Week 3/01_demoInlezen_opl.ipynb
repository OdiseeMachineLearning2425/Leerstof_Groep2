{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d251577",
   "metadata": {},
   "source": [
    "# Computervisie\n",
    "\n",
    "In deze week gaan we vooral focussen op een aantal technieken om te werken met visuele inputs.\n",
    "Als eerste gaan we een aantal technieken zien hoe je deze data op een eenvoudige manier kan inlezen en verwerken.\n",
    "Daarna gaan we een aantal veelgebruikte technieken zijn om meer data aan te maken via varianten van bestaande data.\n",
    "Ten slotte ga je leren hoe je op een efficiente manier modellen kan trainen om classificatie of regressie uit te voeren op een dataset van beelden.\n",
    "\n",
    "## Data inlezen\n",
    "\n",
    "Vorige week heb je geleerd om gestructureerde data in te lezen uit csv-bestanden.\n",
    "Om datasets voor computervisie in te lezen is het vaak complexer omdat typisch elke input in een aparte file staat (1 per beeldje).\n",
    "Het label/target van de figuur kan dan in een csv-bestand staan, in de naam van het bestand of folder staan.\n",
    "Hoe deze data ingeladen wordt hangt dus af van de dataset.\n",
    "In deze notebook staan een aantal voorbeelden om dit te doen met pytorch en met keras.\n",
    "\n",
    "### Pytorch\n",
    "\n",
    "Hieronder staan de meest voorkomende voorbeelden om dit te doen met pytorch:\n",
    "* Veel gebruikte klassieke datasets vind je in de torchvision package, meer bepaald onder datasets.\n",
    "* Via de ImageFolder klasse in het geval dat elke klasse in een aparte subfolder aanwezig is\n",
    "* Je maakt een eigen custom-dataset klasse dat bepaald hoe de figuren ingeladen worden en wat hun label is.\n",
    "\n",
    "Hieronder staan code-voorbeelden van deze technieken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e221cf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Transforms om beelden voor te bereiden\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81063ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Verander de grootte van de afbeelding\n",
    "    transforms.ToTensor(),  # Zet de afbeelding om naar een tensor\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normaliseer de afbeelding\n",
    "])\n",
    "\n",
    "# Laad de dataset\n",
    "dataset = datasets.ImageFolder(root='dataset', transform=transform)\n",
    "\n",
    "# Creëer een DataLoader om batches van gegevens te laden\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Voorbeeld van het verkrijgen van een batch van gegevens\n",
    "for images, labels in dataloader:\n",
    "    print(images.size(), labels.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40446842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.root_dir = image_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Verkrijg de lijst van subfolders (klassen)\n",
    "        self.classes = sorted(os.listdir(image_dir))\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "        \n",
    "        # Verkrijg de lijst van alle afbeeldingen en hun labels\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        for cls in self.classes:\n",
    "            cls_dir = os.path.join(image_dir, cls)\n",
    "            for img_name in os.listdir(cls_dir):\n",
    "                self.image_paths.append(os.path.join(cls_dir, img_name))\n",
    "                self.labels.append(self.class_to_idx[cls])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Pas transformaties toe als die zijn gedefinieerd\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Definieer transformaties\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Creëer een dataset en DataLoader\n",
    "dataset = CustomImageDataset(image_dir='dataset', transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Voorbeeld van het verkrijgen van een batch van gegevens\n",
    "for images, labels in dataloader:\n",
    "    print(images.size(), labels.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b2e389-352b-43a6-abbb-c969d2697278",
   "metadata": {},
   "source": [
    "### Keras\n",
    "\n",
    "De technieken in Keras om dit uit te voeren zijn gelijkaardig.\n",
    "\n",
    "Hieronder staan de meest voorkomende voorbeelden om dit te doen met pytorch:\n",
    "* Veel gebruikte klassieke datasets vind je in de torchvision package, meer bepaald onder datasets.\n",
    "* Via de ImageFolder klasse in het geval dat elke klasse in een aparte subfolder aanwezig is\n",
    "* Je maakt een eigen custom-dataset klasse dat bepaald hoe de figuren ingeladen worden en wat hun label is.\n",
    "\n",
    "Hieronder staan code-voorbeelden van deze technieken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd3300e-2a6d-4f79-a90f-7e3d576f8403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "# Laad de CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Normaliseer de afbeeldingen\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Maak datasets voor training en validatie\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "\n",
    "# Voorbeeld van het verkrijgen van een batch van gegevens\n",
    "for images, labels in train_dataset.take(1):\n",
    "    print(images.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b67a5b-09e8-44e0-9987-469580862985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "# Definieer de dataset directory en batchgrootte\n",
    "dataset_dir = 'dataset'\n",
    "batch_size = 32\n",
    "img_height, img_width = 128, 128\n",
    "\n",
    "# Laad de dataset\n",
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    validation_split=0.2,  # Verdeel in train en validatie\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Voorbeeld van het verkrijgen van een batch van gegevens\n",
    "for images, labels in train_dataset.take(1):\n",
    "    print(images.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32057579-46f6-4ca6-baf5-faf17caad746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "class CustomImageDataset(tf.data.Dataset):\n",
    "    def __new__(cls, image_dir, image_size=(128, 128), batch_size=32):\n",
    "        # Verkrijg alle submappen en hun labels\n",
    "        class_names = sorted(os.listdir(image_dir))\n",
    "        class_to_label = {class_name: idx for idx, class_name in enumerate(class_names)}\n",
    "        \n",
    "        # Verkrijg de paden en labels voor elke afbeelding\n",
    "        image_paths = []\n",
    "        labels = []\n",
    "        for class_name in class_names:\n",
    "            class_path = os.path.join(image_dir, class_name)\n",
    "            for img_name in os.listdir(class_path):\n",
    "                image_paths.append(os.path.join(class_path, img_name))\n",
    "                labels.append(class_to_label[class_name])\n",
    "        \n",
    "        # Functie om een afbeelding te laden en te normaliseren\n",
    "        def load_image(image_path, label):\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            image = image.resize(image_size)\n",
    "            image = np.array(image) / 255.0  # Normaliseer de afbeelding\n",
    "            return image, label\n",
    "        \n",
    "        # Generator functie om data op te halen\n",
    "        def generator():\n",
    "            for img_path, lbl in zip(image_paths, labels):\n",
    "                yield load_image(img_path, lbl)\n",
    "        \n",
    "        # Creëer een TensorFlow dataset van de generator\n",
    "        dataset = tf.data.Dataset.from_generator(\n",
    "            generator,\n",
    "            output_signature=(\n",
    "                tf.TensorSpec(shape=(image_size[0], image_size[1], 3), dtype=tf.float32),\n",
    "                tf.TensorSpec(shape=(), dtype=tf.int32)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Batch en shuffle de data\n",
    "        dataset = dataset.batch(batch_size).shuffle(buffer_size=1000)\n",
    "        return dataset\n",
    "\n",
    "# Voorbeeld van het gebruik van de CustomImageDataset\n",
    "dataset_dir = 'dataset'\n",
    "dataset = CustomImageDataset(image_dir=dataset_dir)\n",
    "\n",
    "# Voorbeeld van het verkrijgen van een batch van gegevens\n",
    "for images, labels in dataset.take(1):\n",
    "    print(images.shape, labels.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d5e8e3a19af5ceb2434683dff87da6345c3b29f7eb0a8a138558c07d014a01cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
