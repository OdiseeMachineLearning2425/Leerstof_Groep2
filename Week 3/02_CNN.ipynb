{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3ca5ca0-88fc-4798-bf66-dabf7f0a4aa2",
   "metadata": {},
   "source": [
    "# Computer visie\n",
    "\n",
    "Deze notebook staat in het teken van computer visie.\n",
    "Dit deel van Machine Learning is tegenwoordig heel populair en behaalt door middel van Deep Learning neurale netwerken heel goede resultaten bij het interpreteren van beelden en video.\n",
    "De toepassingen van Computer visie zijn omvangrijk, bijvoorbeeld:\n",
    "* Medische wereld: interpreteren scans, robots om te helpen bij kinesie therapie\n",
    "* Mobiliteit: Zelfrijdende auto's\n",
    "* Productie: Magazijnen waar robots zelf items halen of kijken hoe ze iets in elkaar moeten steken\n",
    "* Gaming: Geavanceerde bots\n",
    "* Media: Maken en detecteren van deep fakes/misinformatie\n",
    "\n",
    "In deze domeinen wordt computervisie gebruikt zowel als regressie en classificatie techniek. \n",
    "Andere problemen die met computervisie opgelost kunnen worden zijn bijvoorbeeld object detection of image segmentation.\n",
    "Deze technieken worden later in de leermodule bestudeerd.\n",
    "\n",
    "## CNN\n",
    "\n",
    "Op basis van de leerstof van de vorige module gebruik je meerdere dense-layers om een neuraal netwerk te maken voor regressie of classificatie..\n",
    "Computer visie is echter een complex probleem waar het onvoldoende is om individuele pixelwaarden te weten voor een goede classificatie uit te voeren.\n",
    "Indien je dit toch met een klassiek fully-connected neuraal netwerk te doen zou je heel veel neuronen, gewichten en lagen moeten hebben om deze verbanden goed te capteren.\n",
    "\n",
    "De state-of-the-art neurale netwerken binnen computer visie plaatsen eerst een aantal lagen voor het neurale netwerken waarbij deze features geextraheerd worden.\n",
    "\n",
    "Deze neurale netwerken worden Convolutionele Neurale Netwerken genoemd (CNN).\n",
    "De naam hiervan komt voort uit het feit dat ze gebruik maken van Convolutionele lagen.\n",
    "Naast deze convolutionele lagen wordt er ook vaak gebruik gemaakt van Pooling lagen om de dimensies te reduceren en zo de performantie te verbeteren.\n",
    "\n",
    "Een goede uitleg met grafische steuntjes kan je vinden op [deze pagina](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53).\n",
    "\n",
    "### Convolutionele lagen\n",
    "\n",
    "De basis van een convolutionele laag is het concept van een convolutie.\n",
    "Een convolutie is een mathematische operatie waarbij data uit verschillende bronnen wordt verbonden/samengevoegd.\n",
    "In beeldverwerking wordt dit al lang gebruikt om bijvoorbeeld een blur-effect te introduceren, ruis te verminderen of randen scherper te maken. \n",
    "\n",
    "In neurale netwerken worden convolutionele lagen gebruikt om randen te detecteren.\n",
    "In de eerste laag zijn dit letterlijk de randen/lijnen van de figuur maar dieper liggende lagen detecteren hogere orde features zoals gezichten, banden, ogen, ...\n",
    "\n",
    "Deze convolutie/feature extraction wordt uitgevoerd door een kernel. Dit is een kleine matrix die een aantal pixelwaarden samenvoegd met bepaalde gewichten. Deze gewichten worden getrained.\n",
    "Let wel op dat dezelfde kernel gebruikt wordt voor een hele feature-map. Hierdoor wordt het aantal gewichten beperkt.\n",
    "Elke laag bestaat uit meerdere van deze kernels die elk een andere feature leren extraheren.\n",
    "\n",
    "Bij het opstellen van een convolutionele laag moet je een aantal zaken kiezen. Deze keuzes bepalen de dimensies van de outputlaag en de structuur van de onderliggende lagen dus je bestudeerd best de dimensies van de in- en output van deze lagen om vlot te kunnen werken.\n",
    "\n",
    "De hyperparameters van een convolutionele laag zijn:\n",
    "* Dimensies van de input\n",
    "    * 1D -> convolutie in de tijd\n",
    "    * 2D -> convolutie over beelden\n",
    "    * 3D -> convolutie over volumes, bvb video (images in de tijd) of 3d-modellen bij medische beeldvorming\n",
    "* De kernel-dimensie: hoe groot is het venster waarin pixels samengevoegd worden\n",
    "    * Typisch 3x3 of 5x5 (deze getallen zijn oneven zodat er een centrum pixel is, normaal ook gelijk in beide dimensies maar dat is niet verplicht)\n",
    "    * Hoe kleiner de figuur hoe kleiner je je kernel wilt. Het is belangrijk om lokale data te gebruiken\n",
    "* De stride: Hoeveel waarden/pixels schuift de kernel op elke stappen\n",
    "    * Vaak 1 maar kan ook 2 of 3 zijn\n",
    "* Padding: Hoe vang je de gevallen op dat de kernel buiten de figuur zou komen\n",
    "    * No-padding: Kernel kan niet buiten de randen van de figuur gaan (valid padding in tensorflow). Hierdoor kan de dimensie van de output verkleind worden\n",
    "    * Zero-Padding: Nullen worden toegevoegd indien de kernel buiten de randen van de figuur zou gaan (same padding in tensorflow)\n",
    "* Aantal kernels: Hoeveel keer dat we deze convolutie willen uitvoeren = aantal \"feature maps\" die uit de laag komen = aantal \"features\" die herkend worden zoals oren, ogen, banden, ...\n",
    "* Activation function\n",
    "* Regularizers\n",
    "\n",
    "Omdat een aantal van deze operaties de grootte van de figuren beinvloed gaan we dit eerst inoefenen aan de hand van een aantal voorbeelden.\n",
    "Hierbij gaan we uit van de figuren die we hierboven berekend hebben die RGB beelden zijn (drie kanalen) van 32x32 pixels.\n",
    "\n",
    "Wat is de output van een convolutionele laag met de hyperparameters:\n",
    "* 1 kernel, Kernel=3x3, stride=1, padding = zero/same padding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03993ffb-4114-4827-bb85-aa17f1c1bcdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 32, 32])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Maak dummy data: batch van 5 afbeeldingen, elk van 32x32 pixels met 3 kleurkanalen (RGB)\n",
    "batch_size = 5\n",
    "img_height, img_width, channels = 32, 32, 3\n",
    "dummy_images = torch.rand(batch_size, channels, img_height, img_width)\n",
    "dummy_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21b3c53e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 32, 32])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_laag = nn.Conv2d(in_channels=3, out_channels=1, kernel_size=3, stride=1, padding=1)\n",
    "conv_laag(dummy_images).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4795860-5b17-4ff8-87f9-516812949ab3",
   "metadata": {},
   "source": [
    "* 5 kernel, Kernel=3x3, stride=1, padding = no/valid padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18d47f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 5, 30, 30])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_laag = nn.Conv2d(in_channels=3, out_channels=5, kernel_size=3, stride=1, padding=0)\n",
    "conv_laag(dummy_images).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8986230-753d-43b4-9e94-e93e6227356b",
   "metadata": {},
   "source": [
    "* 5 kernel, Kernel=5x5, stride=2, padding = zero/same padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faa95d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 5, 16, 16])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_laag = nn.Conv2d(in_channels=3, out_channels=5, kernel_size=5, stride=2, padding=2)\n",
    "conv_laag(dummy_images).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f3404f-0fbf-4df0-9eb4-996958d5c950",
   "metadata": {},
   "source": [
    "* 5 kernel, Kernel=5x5, stride=2, padding = no/valid padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0ee708b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 5, 14, 14])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_laag = nn.Conv2d(in_channels=3, out_channels=5, kernel_size=5, stride=2, padding=0)\n",
    "conv_laag(dummy_images).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b3bf33-f7e1-4f58-aaed-b64b36a632c7",
   "metadata": {},
   "source": [
    "### Pooling lagen\n",
    "\n",
    "Een probleem/beperking met het concept van convolutionele lagen is dat kleine beweging van de feature resulteren in een andere feature map/andere output. \n",
    "Dit komt omdat de convolutie de exacte positie van de feature bijhoudt.\n",
    "\n",
    "De impact van deze kleine veranderingen (die bijvoorbeeld de impact zijn van onze augmentaties) wordt typisch vermeden door down-sampling uit te voeren. \n",
    "Hierdoor bekomen we een lagere resolutie waar echter nog steeds de belangrijkste en grootste features in gecapteerd zijn. \n",
    "\n",
    "In neurale netwerken kan deze downsampling uitgevoerd worden door de stride van de convolutie doorheen het beeld te vergroten.\n",
    "Dit is echter een niet zo robuste aanpak en typisch wordt er gekozen om gebruik te maken van een pooling laag.\n",
    "\n",
    "Dit is een laag die toegevoegd wordt na de activatiefunctie van de convolutionele laag.\n",
    "Deze pooling laag voert dan deze downsampling uit door een bepaalde operatie uit te voeren.\n",
    "Veruit de meest gebruikte operaties hiervoor zijn:\n",
    "* Average pooling: Gemiddelde feature aanwezig in de buurt\n",
    "* Maximum pooling: Sterkste, meest prominente, meest duidelijke feature\n",
    "\n",
    "Deze operatie op zich voert nog geen downsampling uit.\n",
    "Het downsamplen komt voort uit het feit dat deze laag een kleine groep pixels bekijkt (kernel/filter) en dit kijkvenster met een bepaalde stap verschuift (stride).\n",
    "**In bijna alle gevallen wordt gebruik gemaakt van een 2x2 venster dat verschuift met een stap van 2.**\n",
    "Dit houdt in dat de dimensie van de input gehalveerd wordt door het toepassen van een pooling laag\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1052aec0-566d-4a11-aa35-d493458b3408",
   "metadata": {},
   "source": [
    "Indien we een standaard MaxPooling laag (filter of 2x2 en stride of 2) uitvoeren op de originele figuur (32x32x3), welke dimensie heeft de output dan?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70670dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 16, 16])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooling = nn.MaxPool2d(2) # we stellen enkel de kernel_size in op 2 (default is stride=kernel_size)\n",
    "# stride 2 zorgt ervoor dat breedte en lengte deeld door 2 (aantal kanalen blijft gelijk)\n",
    "pooling(dummy_images).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84197f7a-84a1-4a4a-8928-6f0551b7efd7",
   "metadata": {},
   "source": [
    "### Volledig netwerk\n",
    "\n",
    "Een convolutioneel Neuraal Netwerken bestaat uit dus eerst 1 of meerdere convolutionele lagen gevolgd door een pooling laag. \n",
    "Deze twee lagen worden afgewisseld tot je denkt voldoende diepte te hebben. Dit hangt af van de input van je netwerk en wat je probeert te bereiken. \n",
    "Wanneer er gestopt wordt met de convolutionele en pooling lagen is er een Flatten layer.\n",
    "Deze laag doet niet zo veel behalve de dimensie van de tensor aanpassen zodat het een 1-dimensionele rij wordt.\n",
    "Dit kan dan als input dienen voor een fully-connected neuraal netwerk bestaande uit 1 of meerdere Dense lagen.\n",
    "\n",
    "Een voorbeeld waar een volledig CNN uitgelegd worden kan je [hier](https://towardsdatascience.com/the-most-intuitive-and-easiest-guide-for-convolutional-neural-network-3607be47480) bestuderen.\n",
    "Hieronder gaan we het voorbeeld waarmee we hierboven begonnen waren verder afwerken.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14c7b6b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    # convolutioneel gedeelte (afwisselend conv2d lagen en maxpool lagen)\n",
    "    nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2), # op dit punt is de dimensie in l en b / 2\n",
    "    nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1), # pas op (in_channels nu 16)\n",
    "    # out_channels laten we typisch toenemen (diepere lagen = complexere features (gezichten ipv oren) = meer opties\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    # flatten gedeelte\n",
    "    nn.Flatten(), # resulteert in dimensie 2048 = out_channels * lengte einde conv deel * breedte einde conv deel\n",
    "    # fully-connected gedeelte\n",
    "    nn.Linear(2048, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 10) #  multi-class classificatie met 10 (veronderstelling)\n",
    ")\n",
    "\n",
    "model(dummy_images).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0953408b-c249-4ec2-9f42-0d06c745e297",
   "metadata": {},
   "source": [
    "## Oefening\n",
    "\n",
    "Hier gaan we werken met een standaard classificatieprobleem binnen het domein van computervisie, namelijk de CIFAR10-dataset.\n",
    "Deze dataset bestaat uit 60000 32x32 kleurbeelden (50000 trainingsdata, 10000 testdata). \n",
    "Er zijn 10 mogelijke klassen in deze dataset met 6000 beelden per klasse.\n",
    "De mogelijke klassen zijn:\n",
    "* airplane \n",
    "* automobile \n",
    "* bird \n",
    "* cat \n",
    "* deer \n",
    "* dog \n",
    "* frog \n",
    "* horse \n",
    "* ship \n",
    "* truck\n",
    "\n",
    "Schrijf hieronder 2 keer (1 met pytorch en 1 keer met keras) de nodige code om de volgende stappen uit te voeren om deze classificatieopdracht uit te voeren.\n",
    "Let op de volgende opmerkingen:\n",
    "* Zorg voor schaling zodat de waarden tussen 0 en 1 liggen van de pixel-waarden.\n",
    "* Toon op het einde een batch met bijhorende predicties en echte targets.\n",
    "\n",
    "### Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "499b9580-ef83-490e-92d9-48afc3930100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "# Transforms om beelden voor te bereiden\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "batch_size=32\n",
    "\n",
    "# Load the dataset\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "testset = datasets.CIFAR10(root='./datatest', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "971d34a0-05b8-4021-875e-e3c7f7ce3e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch 100] loss: 0.848\n",
      "[Epoch 1, Batch 200] loss: 0.048\n",
      "[Epoch 1, Batch 300] loss: 0.047\n",
      "[Epoch 1, Batch 400] loss: 0.047\n",
      "[Epoch 1, Batch 500] loss: 0.047\n",
      "[Epoch 1, Batch 600] loss: 0.046\n",
      "[Epoch 1, Batch 700] loss: 0.048\n",
      "[Epoch 1, Batch 800] loss: 0.049\n",
      "[Epoch 1, Batch 900] loss: 0.047\n",
      "[Epoch 1, Batch 1000] loss: 0.048\n",
      "[Epoch 1, Batch 1100] loss: 0.047\n",
      "[Epoch 1, Batch 1200] loss: 0.047\n",
      "[Epoch 1, Batch 1300] loss: 0.048\n",
      "[Epoch 1, Batch 1400] loss: 0.048\n",
      "[Epoch 1, Batch 1500] loss: 0.047\n",
      "[Epoch 2, Batch 100] loss: 0.766\n",
      "[Epoch 2, Batch 200] loss: 0.042\n",
      "[Epoch 2, Batch 300] loss: 0.040\n",
      "[Epoch 2, Batch 400] loss: 0.040\n",
      "[Epoch 2, Batch 500] loss: 0.041\n",
      "[Epoch 2, Batch 600] loss: 0.042\n",
      "[Epoch 2, Batch 700] loss: 0.041\n",
      "[Epoch 2, Batch 800] loss: 0.042\n",
      "[Epoch 2, Batch 900] loss: 0.042\n",
      "[Epoch 2, Batch 1000] loss: 0.040\n",
      "[Epoch 2, Batch 1100] loss: 0.043\n",
      "[Epoch 2, Batch 1200] loss: 0.043\n",
      "[Epoch 2, Batch 1300] loss: 0.043\n",
      "[Epoch 2, Batch 1400] loss: 0.041\n",
      "[Epoch 2, Batch 1500] loss: 0.041\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Define a loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs=2\n",
    "print_every = 100\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):  # Number of epochs\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        # stap 1: begin van een nieuwe gradient\n",
    "        optimizer.zero_grad()\n",
    "        # stap 2: maak voorspellingen\n",
    "        outputs = model(inputs)\n",
    "        # stap 3: bereken de loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        # stap 4: train de gewichten\n",
    "        loss.backward()\n",
    "       \n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % print_every == print_every-1:  # Print every 2000 batches\n",
    "            print(f'[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # evaluatie\n",
    "    # stap 1: bereken geen afgeleiden\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "            inputs, labels = data\n",
    "    \n",
    "            # stap 2: maak voorspellingen\n",
    "            outputs = model(inputs)\n",
    "            # stap 3: bereken de test loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            if i % print_every == print_every-1:  # Print every 2000 batches\n",
    "                print(f'[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 2000:.3f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5bb112-ea95-44fe-93b2-90b1508761fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_inputs, test_labels = next(iter(testloader))\n",
    "test_outputs = model(test_inputs)\n",
    "_, predictions = torch.max(test_outputs, 1)\n",
    "\n",
    "print(test_labels)\n",
    "print(predictions)\n",
    "\n",
    "# Print the image, true labels, and predicted labels\n",
    "def imshow(img):\n",
    "    img = img.permute(1, 2, 0).numpy()  # Convert back to HxWxC\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "# Print images\n",
    "imshow(torchvision.utils.make_grid(test_inputs))\n",
    "print('GroundTruth: ', ' '.join(f'{trainset.classes[test_labels[j]]:5s}' for j in range(batch_size)))\n",
    "print('Predicted:  ', ' '.join(f'{trainset.classes[predictions[j]]:5s}' for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688d55dd-81f0-4ab3-8774-9422c3f1654a",
   "metadata": {},
   "source": [
    "### Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0963fe7-b08f-4075-958a-060fa376aac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Rescaling\n",
    "import keras\n",
    "\n",
    "# Laad en bereid de CIFAR-10 dataset voor\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Min-Max scaling naar [0, 1]\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Definieer het CNN-model met tf.keras.Sequential\n",
    "model = Sequential([\n",
    "    Rescaling(1.0/255.0),\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile het model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train het model\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=64,\n",
    "                    validation_split=0.1, verbose=2)\n",
    "\n",
    "# Evalueer het model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f'\\nTest accuracy: {test_acc:.4f}')\n",
    "\n",
    "# Maak voorspellingen\n",
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fffbc37-18f5-408d-aa92-f7f929137a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print een batch van testafbeeldingen en hun voorspellingen\n",
    "def plot_images(images, labels, predictions, class_names):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(len(images)):\n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        plt.imshow(images[i]/255.0)\n",
    "        plt.title(f'True: {class_names[labels[i][0]]}\\nPred: {class_names[np.argmax(predictions[i])]}')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# CIFAR-10 klasse namen\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# Plot een batch van testafbeeldingen\n",
    "plot_images(x_test[:25], y_test[:25], predictions[:25], class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf52cb34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
